{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n",
      "Collecting more-itertools>=8.5.0 (from inflect)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "                                              0.0/61.0 kB ? eta -:--:--\n",
      "     ------                                   10.2/61.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 61.0/61.0 kB 805.0 kB/s eta 0:00:00\n",
      "Collecting typeguard>=4.0.1 (from inflect)\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\roydo\\appdata\\roaming\\python\\python311\\site-packages (from typeguard>=4.0.1->inflect) (4.12.2)\n",
      "Installing collected packages: typeguard, more-itertools, inflect\n",
      "Successfully installed inflect-7.4.0 more-itertools-10.5.0 typeguard-4.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q langchain sentence-transformers cohere\n",
    "# !pip install rank_bm25\n",
    "# !pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.metadata['file_name'] = doc.metadata['source']\n",
    "    #print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1872010fe90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_vectorstore_hugging_face_v1 = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_hugging_face_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_hugging_face_v1.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and using vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'label': 'Response 3', 'source': 'travel.json', 'file_name': 'travel.json'}, page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}'),\n",
       " Document(metadata={'label': 'Response 4', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}, page_content='{\"Roydon\": \"No, I had to borrow money from a friend to get back home.\", \"Xavier\": \"That must have been a really stressful experience.\"}'),\n",
       " Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'file_name': 'football2.json'}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}'),\n",
       " Document(metadata={'label': 'Response 6', 'source': 'football.json', 'file_name': 'football.json'}, page_content='{\"Roydon\": \"Arteta has been making some good decisions lately, so I have faith in him. How about Ole Gunnar Solskjaer?\", \"John\": \"Solskjaer has been improving as a manager, but there\\'s still room for growth. It\\'ll be interesting to see how both managers perform this season. What\\'s your prediction for Arsenal\\'s first match?\"}'),\n",
       " Document(metadata={'label': 'Response 7', 'source': 'travel.json', 'file_name': 'travel.json'}, page_content='{\"Roydon\": \"Easy for you to say. You weren\\'t the one stuck in a foreign country with nothing going right.\", \"Dory\": \"I know, but sometimes these things happen. You just have to try and make the best of it.\"}')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "docs_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `CohereRerank` was deprecated in LangChain 0.0.30 and will be removed in 0.3.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import CohereRerank`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'label': 'Response 3', 'source': 'travel.json', 'file_name': 'travel.json', 'relevance_score': 0.95177364}, page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}'),\n",
       " Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'file_name': 'football2.json', 'relevance_score': 0.896614}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}'),\n",
       " Document(metadata={'label': 'Response 7', 'source': 'travel.json', 'file_name': 'travel.json', 'relevance_score': 0.85645247}, page_content='{\"Roydon\": \"Easy for you to say. You weren\\'t the one stuck in a foreign country with nothing going right.\", \"Dory\": \"I know, but sometimes these things happen. You just have to try and make the best of it.\"}')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re ranking\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = CohereRerank(cohere_api_key=os.environ['COHERE_API_KEY'])\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and retrieve normally using semantic search\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "loaded_faiss_vs_v3 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\faiss_vs_v3\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== \n",
      " {'label': 'Response 1', 'source': 'football2.json', 'file_name': 'football2.json'}\n",
      "{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn't they?\"}\n",
      "============================== \n",
      " {'label': 'Response 11', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}\n",
      "{\"Roydon\": \"You too, Xavier.\"}\n",
      "============================== \n",
      " {'label': 'Response 1', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}\n",
      "{\"Roydon\": \"I can't believe what happened to me in Thailand.\", \"Xavier\": \"What happened?\"}\n"
     ]
    }
   ],
   "source": [
    "# Normal semantic search\n",
    "query = \"What have you been up to Roydon?\"\n",
    "context = loaded_faiss_vs_v3.similarity_search(query, k=3)\n",
    "\n",
    "for con in context:\n",
    "    print(\"=\" * 30, \"\\n\", con.metadata)\n",
    "    print(con.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_vectordb = loaded_faiss_vs_v3.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'file_name': 'football2.json'}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}'),\n",
       " Document(metadata={'label': 'Response 4', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}, page_content='{\"Roydon\": \"No, I had to borrow money from a friend to get back home.\", \"Xavier\": \"That must have been a really stressful experience.\"}'),\n",
       " Document(metadata={'label': 'Response 11', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}, page_content='{\"Roydon\": \"You too, Xavier.\"}'),\n",
       " Document(metadata={'label': 'Response 6', 'source': 'football.json', 'file_name': 'football.json'}, page_content='{\"Roydon\": \"Arteta has been making some good decisions lately, so I have faith in him. How about Ole Gunnar Solskjaer?\", \"John\": \"Solskjaer has been improving as a manager, but there\\'s still room for growth. It\\'ll be interesting to see how both managers perform this season. What\\'s your prediction for Arsenal\\'s first match?\"}'),\n",
       " Document(metadata={'label': 'Response 1', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json'}, page_content='{\"Roydon\": \"I can\\'t believe what happened to me in Thailand.\", \"Xavier\": \"What happened?\"}'),\n",
       " Document(metadata={'label': 'Response 3', 'source': 'travel.json', 'file_name': 'travel.json'}, page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "docs_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'label': 'Response 3', 'source': 'travel.json', 'file_name': 'travel.json', 'relevance_score': 0.9518632}, page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}'),\n",
       " Document(metadata={'label': 'Response 11', 'source': 'next_trip2.json', 'file_name': 'next_trip2.json', 'relevance_score': 0.9073122}, page_content='{\"Roydon\": \"You too, Xavier.\"}'),\n",
       " Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'file_name': 'football2.json', 'relevance_score': 0.8962514}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cohere reranking\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = CohereRerank(cohere_api_key=os.environ['COHERE_API_KEY'])\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using metrics score for few shot prompting responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Embedding with ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of responses\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and retrieve normally using semantic search\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "loaded_faiss_vs_v3 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\faiss_vs_v3\", embeddings=open_ai_embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ensemble retriever\n",
    "retriever_vectordb = loaded_faiss_vs_v3.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn't they?\"}{\"Roydon\": \"No, I had to borrow money from a friend to get back home.\", \"Xavier\": \"That must have been a really stressful experience.\"}{\"Roydon\": \"You too, Xavier.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "contexts = \"\"\n",
    "for context in docs_rel_top_3:\n",
    "    contexts += context.page_content\n",
    "\n",
    "print(contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/rag_few_shot_ensemble_v1.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Embedding with ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}{\"Roydon\": \"No, I had to borrow money from a friend to get back home.\", \"Xavier\": \"That must have been a really stressful experience.\"}{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn't they?\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "contexts = \"\"\n",
    "for context in docs_rel_top_3:\n",
    "    contexts += context.page_content\n",
    "\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v2.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare between original and the 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS \n",
    "file_path_rag_few_shot = 'testing_json/data_sample_rag_test_prompt_engineered_v2.json'\n",
    "file_path_ensemble_open_ai = 'testing_json/Improve_RAG/rag_few_shot_ensemble_v1.json'\n",
    "file_path_ensemble_hf = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v2.json.'\n",
    "\n",
    "with open(file_path_rag_few_shot, 'r') as json_file:\n",
    "    rag_data_few_shot = json.load(json_file)\n",
    "\n",
    "with open(file_path_ensemble_open_ai, 'r') as json_file:\n",
    "    rag_ensemble_open_ai = json.load(json_file)\n",
    "\n",
    "with open(file_path_ensemble_hf, 'r') as json_file:\n",
    "    rag_ensemble_hf = json.load(json_file)\n",
    "\n",
    "rag_dataset_few_shot = Dataset.from_dict(rag_data_few_shot)\n",
    "rag_dataset_ensemble_open_ai = Dataset.from_dict(rag_ensemble_open_ai)\n",
    "rag_dataset_ensemble_hf = Dataset.from_dict(rag_ensemble_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 40/40 [00:27<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.11it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:59<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "rag_dataset_few_shot_score = evaluate(rag_dataset_few_shot, metrics=[answer_relevancy, answer_correctness, context_precision, context_recall])\n",
    "rag_dataset_ensemble_open_ai_score = evaluate(rag_dataset_ensemble_open_ai, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "rag_dataset_ensemble_hf_score = evaluate(rag_dataset_ensemble_hf, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_few_shot_df = rag_dataset_few_shot_score.to_pandas()\n",
    "rag_ensemble_open_ai_df = rag_dataset_ensemble_open_ai_score.to_pandas()\n",
    "rag_ensemble_hf_df= rag_dataset_ensemble_hf_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Few Shot=========================\n",
      "Non-RAG Average Answer Relevancy: 0.452734835146927\n",
      "Non-RAG Average Answer Correctness: 0.6440070072030675\n",
      "Non-RAG Average Context Precision: 0.89999999991\n",
      "Non-RAG Average Context Recall: 0.475\n",
      "=========================Ensemble Open AI=========================\n",
      "RAG Average Answer Relevancy: 0.468133850976659\n",
      "RAG Average Answer Correctness: 0.4664450979906115\n",
      "RAG Average Context Precision: 0.69999999993\n",
      "RAG Average Context Recall: 0.4\n",
      "=========================Ensemble HF=========================\n",
      "RAG Average Answer Relevancy: 0.3743571687636189\n",
      "RAG Average Answer Correctness: 0.5205250062605699\n",
      "RAG Average Context Precision: 0.69999999993\n",
      "RAG Average Context Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate average for non_rag_df\n",
    "rag_few_shot_relevancy = rag_few_shot_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_few_shot_answer_correctness = rag_few_shot_df['answer_correctness'].mean(skipna=True)\n",
    "rag_few_shot_avg_precision = rag_few_shot_df['context_precision'].mean(skipna=True)\n",
    "rag_few_shot_avg_recall = rag_few_shot_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for rag_df\n",
    "rag_ensemble_open_ai_avg_answer_relevancy = rag_ensemble_open_ai_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_open_ai_avg_answer_correctness = rag_ensemble_open_ai_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_open_ai_avg_precision = rag_ensemble_open_ai_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_open_ai_avg_recall = rag_ensemble_open_ai_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for rag_df\n",
    "rag_ensemble_hf_avg_answer_relevancy = rag_ensemble_hf_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness = rag_ensemble_hf_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision = rag_ensemble_hf_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall = rag_ensemble_hf_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Few Shot=========================\")\n",
    "print(\"Non-RAG Average Answer Relevancy:\", rag_few_shot_relevancy)\n",
    "print(\"Non-RAG Average Answer Correctness:\", rag_few_shot_answer_correctness)\n",
    "print(\"Non-RAG Average Context Precision:\", rag_few_shot_avg_precision)\n",
    "print(\"Non-RAG Average Context Recall:\", rag_few_shot_avg_recall)\n",
    "print(\"=========================Ensemble Open AI=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_open_ai_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_open_ai_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_open_ai_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_open_ai_avg_recall)\n",
    "print(\"=========================Ensemble HF=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/ensemble_open_ai_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_open_ai_df.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/ensemble_hf_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.1.6 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_ai scores\n",
    "ensemble_open_ai_scores = []\n",
    "ensemble_open_ai_reasons = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_ensemble_open_ai['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_ensemble_open_ai['question'][i],\n",
    "        actual_output=rag_ensemble_open_ai['answer'][i],\n",
    "        expected_output=rag_ensemble_open_ai['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_open_ai_scores.append(correctness_metric.score)\n",
    "    ensemble_open_ai_reasons.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_open_hf_scores = []\n",
    "ensemble_open_hf_reasons = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_ensemble_hf['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_ensemble_hf['question'][i],\n",
    "        actual_output=rag_ensemble_hf['answer'][i],\n",
    "        expected_output=rag_ensemble_hf['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_open_hf_scores.append(correctness_metric.score)\n",
    "    ensemble_open_hf_reasons.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Load the scores and reasons from the specified Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/g_eval_rag_prompt_engineered_scores_v3.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "g_eval_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "rag_few_shot_scores = g_eval_df['Scores'].tolist()\n",
    "rag_few_shot_reasons = g_eval_df['Reasons'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Few Shot: 0.5545081113816229\n",
      "Average Score for Ensemble Open Ai: 0.602516814829001\n",
      "Average Score for Ensemble HF: 0.6355191874880344\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_open_ai_df = pd.DataFrame({'Scores': ensemble_open_ai_scores, 'Reasons': ensemble_open_ai_reasons})\n",
    "ensemble_hf_df = pd.DataFrame({'Scores': ensemble_open_hf_scores, 'Reasons': ensemble_open_hf_reasons})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "rag_few_shot = sum(rag_few_shot_scores) / len(rag_few_shot_scores)\n",
    "ensemble_open_ai = ensemble_open_ai_df['Scores'].mean()\n",
    "ensemble_hf = ensemble_hf_df['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Few Shot:\", rag_few_shot)\n",
    "print(\"Average Score for Ensemble Open Ai:\", ensemble_open_ai)\n",
    "print(\"Average Score for Ensemble HF:\", ensemble_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/g_eval_ensemble_open_ai_v1.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_open_ai_df.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/g_eval_ensemble_hf_v2.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble HF with Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generation of responses\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Cohere reranking\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = CohereRerank(cohere_api_key=os.environ['COHERE_API_KEY'])\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn't they?\"}{\"Roydon\": \"Easy for you to say. You weren't the one stuck in a foreign country with nothing going right.\", \"Dory\": \"I know, but sometimes these things happen. You just have to try and make the best of it.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "\n",
    "contexts = \"\"\n",
    "for context in compressed_docs:\n",
    "    contexts += context.page_content\n",
    "\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for ensemble with reranking\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_rerank_v3.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>G-Eval_Scores</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What have you been up to Roydon?</td>\n",
       "      <td>Response 1: I tried to, but everywhere I went,...</td>\n",
       "      <td>['{\"Roydon\": \"I tried to, but everywhere I wen...</td>\n",
       "      <td>Response 1: I've been watching Arsenal games h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211592</td>\n",
       "      <td>The main content of response 3 in the actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Woah really how is Arsenal doing right now then?</td>\n",
       "      <td>Response 1: Arsenal is currently in a good pos...</td>\n",
       "      <td>['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...</td>\n",
       "      <td>Response 1: Arsenal is doing well, did you cat...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.597107</td>\n",
       "      <td>Two out of the three responses in the actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice what breed is your new pet dog?</td>\n",
       "      <td>Response 1: It's a Golden Retriever. \\nRespons...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714982</td>\n",
       "      <td>The main content of all responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>So what you planning to do with your pet dog?</td>\n",
       "      <td>Response 1: I'm planning to teach him some tri...</td>\n",
       "      <td>['{\"Roydon\": \"Absolutely! I\\'m planning to tea...</td>\n",
       "      <td>Response 1: I'm planning to take him on long h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.506720</td>\n",
       "      <td>Actual output response 1 is similar to expecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How was your trip to thailand?</td>\n",
       "      <td>Response 1: It was a total disaster, nothing w...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe how terrible my...</td>\n",
       "      <td>Response 1: It was a horrible experience and I...</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.910776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941470</td>\n",
       "      <td>All the main content of the actual responses m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What happened in thailand?</td>\n",
       "      <td>Response 1: My flight got cancelled and my lug...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe what happened t...</td>\n",
       "      <td>Response 1: I got scammed by a taxi driver and...</td>\n",
       "      <td>0.911640</td>\n",
       "      <td>0.228831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613643</td>\n",
       "      <td>One of the main content in the actual output (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What channel are you planning to create for yo...</td>\n",
       "      <td>Response 1: I'm thinking of creating a channel...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to create a special I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746633</td>\n",
       "      <td>Two of the main contents of the responses in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How was your trip to thailand and any new trav...</td>\n",
       "      <td>Response 1: Thailand was a disaster, but Japan...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t wait to immerse myself ...</td>\n",
       "      <td>Response 1: It was a horrible experience. I go...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.546592</td>\n",
       "      <td>None of the main content in the responses gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>I heard you got a new pet dog how is he? What ...</td>\n",
       "      <td>Response 1: He's doing great, thanks for askin...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is so fun to be with. Im planni...</td>\n",
       "      <td>0.897573</td>\n",
       "      <td>0.733547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861327</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hows your new pet dog? What breed is he?</td>\n",
       "      <td>Response 1: He's doing great! My new pet dog i...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He brings so much joy to my life. ...</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.441294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615126</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                   What have you been up to Roydon?   \n",
       "1           1   Woah really how is Arsenal doing right now then?   \n",
       "2           2               Nice what breed is your new pet dog?   \n",
       "3           3      So what you planning to do with your pet dog?   \n",
       "4           4                     How was your trip to thailand?   \n",
       "5           5                         What happened in thailand?   \n",
       "6           6  What channel are you planning to create for yo...   \n",
       "7           7  How was your trip to thailand and any new trav...   \n",
       "8           8  I heard you got a new pet dog how is he? What ...   \n",
       "9           9           Hows your new pet dog? What breed is he?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Response 1: I tried to, but everywhere I went,...   \n",
       "1  Response 1: Arsenal is currently in a good pos...   \n",
       "2  Response 1: It's a Golden Retriever. \\nRespons...   \n",
       "3  Response 1: I'm planning to teach him some tri...   \n",
       "4  Response 1: It was a total disaster, nothing w...   \n",
       "5  Response 1: My flight got cancelled and my lug...   \n",
       "6  Response 1: I'm thinking of creating a channel...   \n",
       "7  Response 1: Thailand was a disaster, but Japan...   \n",
       "8  Response 1: He's doing great, thanks for askin...   \n",
       "9  Response 1: He's doing great! My new pet dog i...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['{\"Roydon\": \"I tried to, but everywhere I wen...   \n",
       "1  ['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...   \n",
       "2  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "3  ['{\"Roydon\": \"Absolutely! I\\'m planning to tea...   \n",
       "4  ['{\"Roydon\": \"I can\\'t believe how terrible my...   \n",
       "5  ['{\"Roydon\": \"I can\\'t believe what happened t...   \n",
       "6  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "7  ['{\"Roydon\": \"I can\\'t wait to immerse myself ...   \n",
       "8  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "9  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Response 1: I've been watching Arsenal games h...          0.000000   \n",
       "1  Response 1: Arsenal is doing well, did you cat...          0.000000   \n",
       "2  Response 1: He is a golden retriever, and he's...          0.000000   \n",
       "3  Response 1: I'm planning to take him on long h...          0.000000   \n",
       "4  Response 1: It was a horrible experience and I...          0.995870   \n",
       "5  Response 1: I got scammed by a taxi driver and...          0.911640   \n",
       "6  Response 1: I'm planning to create a special I...          0.000000   \n",
       "7  Response 1: It was a horrible experience. I go...          0.000000   \n",
       "8  Response 1: He is so fun to be with. Im planni...          0.897573   \n",
       "9  Response 1: He brings so much joy to my life. ...          0.938489   \n",
       "\n",
       "   answer_correctness  context_precision  context_recall  G-Eval_Scores  \\\n",
       "0            0.213683                0.0        0.000000       0.211592   \n",
       "1            0.477226                1.0        0.666667       0.597107   \n",
       "2            0.530437                0.0        0.000000       0.714982   \n",
       "3            0.536566                1.0        0.666667       0.506720   \n",
       "4            0.910776                1.0        1.000000       0.941470   \n",
       "5            0.228831                1.0        0.000000       0.613643   \n",
       "6            0.555070                1.0        1.000000       0.746633   \n",
       "7            0.577820                1.0        0.666667       0.546592   \n",
       "8            0.733547                1.0        1.000000       0.861327   \n",
       "9            0.441294                0.0        0.000000       0.615126   \n",
       "\n",
       "                                             Reasons  \n",
       "0  The main content of response 3 in the actual o...  \n",
       "1  Two out of the three responses in the actual o...  \n",
       "2  The main content of all responses in the 'actu...  \n",
       "3  Actual output response 1 is similar to expecte...  \n",
       "4  All the main content of the actual responses m...  \n",
       "5  One of the main content in the actual output (...  \n",
       "6  Two of the main contents of the responses in t...  \n",
       "7  None of the main content in the responses gene...  \n",
       "8  The main content of the responses in the 'actu...  \n",
       "9  The main content of the responses in the 'actu...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAGAS \n",
    "file_path_ensemble_rerank_hf = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_rerank_v3.json'\n",
    "\n",
    "with open(file_path_ensemble_rerank_hf, 'r') as json_file:\n",
    "    rag_ensemble_rerank_hf = json.load(json_file)\n",
    "\n",
    "rag_dataset_ensemble_hf_rerank = Dataset.from_dict(rag_ensemble_rerank_hf)\n",
    "\n",
    "# Load dataset score from excel for RAGAS and g-eval, ensemble hf\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/RAG_Few_Shot_Combined_Eval_HF_Ensemble_v2.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "hf_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "hf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 40/40 [00:22<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# RAGAS Evaluation\n",
    "rag_dataset_ensemble_hf_reranking_score = evaluate(rag_dataset_ensemble_hf_rerank, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_ensemble_hf_rerank_df= rag_dataset_ensemble_hf_reranking_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble HF=========================\n",
      "RAG Average Answer Relevancy: 0.3743571687636189\n",
      "RAG Average Answer Correctness: 0.5205250062605699\n",
      "RAG Average Context Precision: 0.69999999993\n",
      "RAG Average Context Recall: 0.5\n",
      "=========================Ensemble HF Rerank=========================\n",
      "RAG Average Answer Relevancy: 0.284599889611891\n",
      "RAG Average Answer Correctness: 0.5720345380788269\n",
      "RAG Average Context Precision: 0.69999999993\n",
      "RAG Average Context Recall: 0.4666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculate average for rag_hf_rerank_df\n",
    "rag_ensemble_hf_avg_answer_relevancy = hf_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness = hf_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision = hf_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall = hf_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "# Calculate average for rag_hf_rerank_df\n",
    "rag_ensemble_hf_rerank_avg_answer_relevancy = rag_ensemble_hf_rerank_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_rerank_avg_answer_correctness = rag_ensemble_hf_rerank_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_rerank_avg_precision = rag_ensemble_hf_rerank_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_rerank_avg_recall = rag_ensemble_hf_rerank_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble HF=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall)\n",
    "\n",
    "\n",
    "print(\"=========================Ensemble HF Rerank=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_rerank_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_rerank_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_rerank_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_rerank_avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/ensemble_hf_rerank_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_rerank_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.1.7 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_open_hf_rerank_scores = []\n",
    "ensemble_open_hf_rerank_reasons = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_ensemble_hf_rerank['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_ensemble_hf_rerank['question'][i],\n",
    "        actual_output=rag_dataset_ensemble_hf_rerank['answer'][i],\n",
    "        expected_output=rag_dataset_ensemble_hf_rerank['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_open_hf_rerank_scores.append(correctness_metric.score)\n",
    "    ensemble_open_hf_rerank_reasons.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF: 0.6355191874880344\n",
      "Average Score for Ensemble HF Rerank: 0.5903976058086038\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_rerank_df = pd.DataFrame({'Scores': ensemble_open_hf_rerank_scores, 'Reasons': ensemble_open_hf_rerank_reasons})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf = hf_df['G-Eval_Scores'].mean()\n",
    "ensemble_hf_rerank = ensemble_hf_rerank_df['Scores'].mean()\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF:\", ensemble_hf)\n",
    "print(\"Average Score for Ensemble HF Rerank:\", ensemble_hf_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/g_eval_ensemble_hf_rerank_v3.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_rerank_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out varying parameters for ensemble hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v3_0.6_0.4.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v4_0.4_0.6.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons for all 3\n",
    "\n",
    "- 0.5,0.5\n",
    "- 0.4, 0.6\n",
    "- 0.6, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS \n",
    "file_path_ensemble_hf_6_4 = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v3_0.6_0.4.json'\n",
    "file_path_ensemble_hf_4_6 = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v4_0.4_0.6.json'\n",
    "\n",
    "with open(file_path_ensemble_hf_6_4, 'r') as json_file:\n",
    "    rag_ensemble_hf_6_4 = json.load(json_file)\n",
    "\n",
    "with open(file_path_ensemble_hf_4_6, 'r') as json_file:\n",
    "    rag_ensemble_hf_4_6 = json.load(json_file)\n",
    "\n",
    "rag_dataset_ensemble_hf_6_4 = Dataset.from_dict(rag_ensemble_hf_6_4)\n",
    "rag_dataset_ensemble_hf_4_6 = Dataset.from_dict(rag_ensemble_hf_4_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 40/40 [00:21<00:00,  1.90it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:21<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "rag_dataset_ensemble_hf_6_4_score = evaluate(rag_dataset_ensemble_hf_6_4, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "rag_dataset_ensemble_hf_4_6_score = evaluate(rag_dataset_ensemble_hf_4_6, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_ensemble_hf_df_6_4 = rag_dataset_ensemble_hf_6_4_score.to_pandas()\n",
    "rag_ensemble_hf_df_4_6 = rag_dataset_ensemble_hf_4_6_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>G-Eval_Scores</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What have you been up to Roydon?</td>\n",
       "      <td>Response 1: I tried to, but everywhere I went,...</td>\n",
       "      <td>['{\"Roydon\": \"I tried to, but everywhere I wen...</td>\n",
       "      <td>Response 1: I've been watching Arsenal games h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211592</td>\n",
       "      <td>The main content of response 3 in the actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Woah really how is Arsenal doing right now then?</td>\n",
       "      <td>Response 1: Arsenal is currently in a good pos...</td>\n",
       "      <td>['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...</td>\n",
       "      <td>Response 1: Arsenal is doing well, did you cat...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.597107</td>\n",
       "      <td>Two out of the three responses in the actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice what breed is your new pet dog?</td>\n",
       "      <td>Response 1: It's a Golden Retriever. \\nRespons...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714982</td>\n",
       "      <td>The main content of all responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>So what you planning to do with your pet dog?</td>\n",
       "      <td>Response 1: I'm planning to teach him some tri...</td>\n",
       "      <td>['{\"Roydon\": \"Absolutely! I\\'m planning to tea...</td>\n",
       "      <td>Response 1: I'm planning to take him on long h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.506720</td>\n",
       "      <td>Actual output response 1 is similar to expecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How was your trip to thailand?</td>\n",
       "      <td>Response 1: It was a total disaster, nothing w...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe how terrible my...</td>\n",
       "      <td>Response 1: It was a horrible experience and I...</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.910776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941470</td>\n",
       "      <td>All the main content of the actual responses m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What happened in thailand?</td>\n",
       "      <td>Response 1: My flight got cancelled and my lug...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe what happened t...</td>\n",
       "      <td>Response 1: I got scammed by a taxi driver and...</td>\n",
       "      <td>0.911640</td>\n",
       "      <td>0.228831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613643</td>\n",
       "      <td>One of the main content in the actual output (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What channel are you planning to create for yo...</td>\n",
       "      <td>Response 1: I'm thinking of creating a channel...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to create a special I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746633</td>\n",
       "      <td>Two of the main contents of the responses in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How was your trip to thailand and any new trav...</td>\n",
       "      <td>Response 1: Thailand was a disaster, but Japan...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t wait to immerse myself ...</td>\n",
       "      <td>Response 1: It was a horrible experience. I go...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.546592</td>\n",
       "      <td>None of the main content in the responses gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>I heard you got a new pet dog how is he? What ...</td>\n",
       "      <td>Response 1: He's doing great, thanks for askin...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is so fun to be with. Im planni...</td>\n",
       "      <td>0.897573</td>\n",
       "      <td>0.733547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861327</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hows your new pet dog? What breed is he?</td>\n",
       "      <td>Response 1: He's doing great! My new pet dog i...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He brings so much joy to my life. ...</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.441294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615126</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                   What have you been up to Roydon?   \n",
       "1           1   Woah really how is Arsenal doing right now then?   \n",
       "2           2               Nice what breed is your new pet dog?   \n",
       "3           3      So what you planning to do with your pet dog?   \n",
       "4           4                     How was your trip to thailand?   \n",
       "5           5                         What happened in thailand?   \n",
       "6           6  What channel are you planning to create for yo...   \n",
       "7           7  How was your trip to thailand and any new trav...   \n",
       "8           8  I heard you got a new pet dog how is he? What ...   \n",
       "9           9           Hows your new pet dog? What breed is he?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Response 1: I tried to, but everywhere I went,...   \n",
       "1  Response 1: Arsenal is currently in a good pos...   \n",
       "2  Response 1: It's a Golden Retriever. \\nRespons...   \n",
       "3  Response 1: I'm planning to teach him some tri...   \n",
       "4  Response 1: It was a total disaster, nothing w...   \n",
       "5  Response 1: My flight got cancelled and my lug...   \n",
       "6  Response 1: I'm thinking of creating a channel...   \n",
       "7  Response 1: Thailand was a disaster, but Japan...   \n",
       "8  Response 1: He's doing great, thanks for askin...   \n",
       "9  Response 1: He's doing great! My new pet dog i...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['{\"Roydon\": \"I tried to, but everywhere I wen...   \n",
       "1  ['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...   \n",
       "2  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "3  ['{\"Roydon\": \"Absolutely! I\\'m planning to tea...   \n",
       "4  ['{\"Roydon\": \"I can\\'t believe how terrible my...   \n",
       "5  ['{\"Roydon\": \"I can\\'t believe what happened t...   \n",
       "6  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "7  ['{\"Roydon\": \"I can\\'t wait to immerse myself ...   \n",
       "8  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "9  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Response 1: I've been watching Arsenal games h...          0.000000   \n",
       "1  Response 1: Arsenal is doing well, did you cat...          0.000000   \n",
       "2  Response 1: He is a golden retriever, and he's...          0.000000   \n",
       "3  Response 1: I'm planning to take him on long h...          0.000000   \n",
       "4  Response 1: It was a horrible experience and I...          0.995870   \n",
       "5  Response 1: I got scammed by a taxi driver and...          0.911640   \n",
       "6  Response 1: I'm planning to create a special I...          0.000000   \n",
       "7  Response 1: It was a horrible experience. I go...          0.000000   \n",
       "8  Response 1: He is so fun to be with. Im planni...          0.897573   \n",
       "9  Response 1: He brings so much joy to my life. ...          0.938489   \n",
       "\n",
       "   answer_correctness  context_precision  context_recall  G-Eval_Scores  \\\n",
       "0            0.213683                0.0        0.000000       0.211592   \n",
       "1            0.477226                1.0        0.666667       0.597107   \n",
       "2            0.530437                0.0        0.000000       0.714982   \n",
       "3            0.536566                1.0        0.666667       0.506720   \n",
       "4            0.910776                1.0        1.000000       0.941470   \n",
       "5            0.228831                1.0        0.000000       0.613643   \n",
       "6            0.555070                1.0        1.000000       0.746633   \n",
       "7            0.577820                1.0        0.666667       0.546592   \n",
       "8            0.733547                1.0        1.000000       0.861327   \n",
       "9            0.441294                0.0        0.000000       0.615126   \n",
       "\n",
       "                                             Reasons  \n",
       "0  The main content of response 3 in the actual o...  \n",
       "1  Two out of the three responses in the actual o...  \n",
       "2  The main content of all responses in the 'actu...  \n",
       "3  Actual output response 1 is similar to expecte...  \n",
       "4  All the main content of the actual responses m...  \n",
       "5  One of the main content in the actual output (...  \n",
       "6  Two of the main contents of the responses in t...  \n",
       "7  None of the main content in the responses gene...  \n",
       "8  The main content of the responses in the 'actu...  \n",
       "9  The main content of the responses in the 'actu...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.5 0.5 scores\n",
    "\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/RAG_Few_Shot_Combined_Eval_HF_Ensemble_v2.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "hf_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "hf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble HF 0.5, 0.5=========================\n",
      "Non-RAG Average Answer Relevancy: 0.3743571687636189\n",
      "Non-RAG Average Answer Correctness: 0.5205250062605699\n",
      "Non-RAG Average Context Precision: 0.69999999993\n",
      "Non-RAG Average Context Recall: 0.5\n",
      "=========================Ensemble HF 0.6, 0.4=========================\n",
      "RAG Average Answer Relevancy: 0.36526090687001056\n",
      "RAG Average Answer Correctness: 0.5677870677191184\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.6833333333333333\n",
      "=========================Ensemble HF 0.4, 0.6=========================\n",
      "RAG Average Answer Relevancy: 0.27873358142029897\n",
      "RAG Average Answer Correctness: 0.5779282570940589\n",
      "RAG Average Context Precision: 0.49999999995\n",
      "RAG Average Context Recall: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate average for 0.5, 0.5\n",
    "rag_ensemble_hf_avg_answer_relevancy_5_5 = hf_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_5_5 = hf_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_5_5 = hf_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_5_5 = hf_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for 0.6, 0.4\n",
    "rag_ensemble_hf_avg_answer_relevancy_6_4 = rag_ensemble_hf_df_6_4['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_6_4 = rag_ensemble_hf_df_6_4['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_6_4 = rag_ensemble_hf_df_6_4['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_6_4 = rag_ensemble_hf_df_6_4['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for 0.6, 0.4\n",
    "rag_ensemble_hf_avg_answer_relevancy_4_6 = rag_ensemble_hf_df_4_6['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_4_6 = rag_ensemble_hf_df_4_6['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_4_6 = rag_ensemble_hf_df_4_6['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_4_6 = rag_ensemble_hf_df_4_6['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble HF 0.5, 0.5=========================\")\n",
    "print(\"Non-RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_5_5)\n",
    "print(\"Non-RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_5_5)\n",
    "print(\"Non-RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_5_5)\n",
    "print(\"Non-RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_5_5)\n",
    "print(\"=========================Ensemble HF 0.6, 0.4=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_6_4)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_6_4)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_6_4)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_6_4)\n",
    "print(\"=========================Ensemble HF 0.4, 0.6=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_4_6)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_4_6)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_4_6)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_4_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_6_4_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_df_6_4.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_4_6_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_df_4_6.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.1.9 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_hf_scores_6_4 = []\n",
    "ensemble_hf_reasons_6_4 = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_ensemble_hf_6_4['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_ensemble_hf_6_4['question'][i],\n",
    "        actual_output=rag_dataset_ensemble_hf_6_4['answer'][i],\n",
    "        expected_output=rag_dataset_ensemble_hf_6_4['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_hf_scores_6_4.append(correctness_metric.score)\n",
    "    ensemble_hf_reasons_6_4.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_hf_scores_4_6 = []\n",
    "ensemble_hf_reasons_4_6 = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_ensemble_hf_4_6['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_ensemble_hf_4_6['question'][i],\n",
    "        actual_output=rag_dataset_ensemble_hf_4_6['answer'][i],\n",
    "        expected_output=rag_dataset_ensemble_hf_4_6['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_hf_scores_4_6.append(correctness_metric.score)\n",
    "    ensemble_hf_reasons_4_6.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF 0.5,0.5: 0.6355191874880344\n",
      "Average Score for Ensemble HF 0.6,0.4: 0.6276375029535538\n",
      "Average Score for Ensemble HF 0.4,0.6: 0.5456360238792106\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_df_6_4 = pd.DataFrame({'Scores': ensemble_hf_scores_6_4, 'Reasons': ensemble_hf_reasons_6_4})\n",
    "ensemble_hf_df_4_6 = pd.DataFrame({'Scores': ensemble_hf_scores_4_6, 'Reasons': ensemble_hf_reasons_4_6})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf_5_5 = hf_df['G-Eval_Scores'].mean()\n",
    "ensemble_hf_6_4 = ensemble_hf_df_6_4['Scores'].mean()\n",
    "ensemble_hf_4_6 = ensemble_hf_df_4_6['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF 0.5,0.5:\", ensemble_hf_5_5)\n",
    "print(\"Average Score for Ensemble HF 0.6,0.4:\", ensemble_hf_6_4)\n",
    "print(\"Average Score for Ensemble HF 0.4,0.6:\", ensemble_hf_4_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_6_4_v2.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_6_4.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_4_6_v2.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_4_6.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.7, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v5_0.7_0.3.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.8, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v1 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v1\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v1.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    docs_rel_top_3 = docs_rel[:3]\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in docs_rel_top_3:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v6_0.8_0.2.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with 0.6,0.4\n",
    "\n",
    "- 0.6,0.4\n",
    "- 0.7,0.3\n",
    "- 0.8, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS \n",
    "file_path_ensemble_hf_7_3 = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v5_0.7_0.3.json'\n",
    "file_path_ensemble_hf_8_2 = 'testing_json/Improve_RAG/rag_few_shot_ensemble_hf_v6_0.8_0.2.json'\n",
    "\n",
    "with open(file_path_ensemble_hf_7_3, 'r') as json_file:\n",
    "    rag_ensemble_hf_7_3 = json.load(json_file)\n",
    "\n",
    "with open(file_path_ensemble_hf_8_2, 'r') as json_file:\n",
    "    rag_ensemble_hf_8_2 = json.load(json_file)\n",
    "\n",
    "rag_dataset_ensemble_hf_7_3 = Dataset.from_dict(rag_ensemble_hf_7_3)\n",
    "rag_dataset_ensemble_hf_8_2 = Dataset.from_dict(rag_ensemble_hf_8_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset_ensemble_hf_7_3_score = evaluate(rag_dataset_ensemble_hf_7_3, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "rag_dataset_ensemble_hf_8_2_score = evaluate(rag_dataset_ensemble_hf_8_2, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_ensemble_hf_df_7_3 = rag_dataset_ensemble_hf_7_3_score.to_pandas()\n",
    "rag_ensemble_hf_df_8_2 = rag_dataset_ensemble_hf_8_2_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What have you been up to Roydon?</td>\n",
       "      <td>Response 1: I tried to, but everywhere I went,...</td>\n",
       "      <td>['{\"Roydon\": \"I tried to, but everywhere I wen...</td>\n",
       "      <td>Response 1: I've been watching Arsenal games h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Woah really how is Arsenal doing right now then?</td>\n",
       "      <td>Response 1: Arsenal is currently showing great...</td>\n",
       "      <td>['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...</td>\n",
       "      <td>Response 1: Arsenal is doing well, did you cat...</td>\n",
       "      <td>0.844825</td>\n",
       "      <td>0.501332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice what breed is your new pet dog?</td>\n",
       "      <td>Response 1: It's a golden retriever, and he's ...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>0.941946</td>\n",
       "      <td>0.427109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>So what you planning to do with your pet dog?</td>\n",
       "      <td>Response 1: I'm planning to teach him how to f...</td>\n",
       "      <td>['{\"Roydon\": \"Absolutely! I\\'m planning to tea...</td>\n",
       "      <td>Response 1: I'm planning to take him on long h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How was your trip to thailand?</td>\n",
       "      <td>Response 1: It was a total disaster, nothing w...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe how terrible my...</td>\n",
       "      <td>Response 1: It was a horrible experience and I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What happened in thailand?</td>\n",
       "      <td>Response 1: It was a series of unfortunate eve...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe what happened t...</td>\n",
       "      <td>Response 1: I got scammed by a taxi driver and...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What channel are you planning to create for yo...</td>\n",
       "      <td>Response 1: I'm thinking of creating a channel...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to create a special I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How was your trip to thailand and any new trav...</td>\n",
       "      <td>Response 1: Thailand was a disaster, but I'm l...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t wait to immerse myself ...</td>\n",
       "      <td>Response 1: It was a horrible experience. I go...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>I heard you got a new pet dog how is he? What ...</td>\n",
       "      <td>Response 1: He's doing great! I named him Sunn...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is so fun to be with. Im planni...</td>\n",
       "      <td>0.927349</td>\n",
       "      <td>0.887572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hows your new pet dog? What breed is he?</td>\n",
       "      <td>Response 1: He's doing great, thanks for askin...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He brings so much joy to my life. ...</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.731246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                   What have you been up to Roydon?   \n",
       "1           1   Woah really how is Arsenal doing right now then?   \n",
       "2           2               Nice what breed is your new pet dog?   \n",
       "3           3      So what you planning to do with your pet dog?   \n",
       "4           4                     How was your trip to thailand?   \n",
       "5           5                         What happened in thailand?   \n",
       "6           6  What channel are you planning to create for yo...   \n",
       "7           7  How was your trip to thailand and any new trav...   \n",
       "8           8  I heard you got a new pet dog how is he? What ...   \n",
       "9           9           Hows your new pet dog? What breed is he?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Response 1: I tried to, but everywhere I went,...   \n",
       "1  Response 1: Arsenal is currently showing great...   \n",
       "2  Response 1: It's a golden retriever, and he's ...   \n",
       "3  Response 1: I'm planning to teach him how to f...   \n",
       "4  Response 1: It was a total disaster, nothing w...   \n",
       "5  Response 1: It was a series of unfortunate eve...   \n",
       "6  Response 1: I'm thinking of creating a channel...   \n",
       "7  Response 1: Thailand was a disaster, but I'm l...   \n",
       "8  Response 1: He's doing great! I named him Sunn...   \n",
       "9  Response 1: He's doing great, thanks for askin...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['{\"Roydon\": \"I tried to, but everywhere I wen...   \n",
       "1  ['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...   \n",
       "2  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "3  ['{\"Roydon\": \"Absolutely! I\\'m planning to tea...   \n",
       "4  ['{\"Roydon\": \"I can\\'t believe how terrible my...   \n",
       "5  ['{\"Roydon\": \"I can\\'t believe what happened t...   \n",
       "6  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "7  ['{\"Roydon\": \"I can\\'t wait to immerse myself ...   \n",
       "8  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "9  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Response 1: I've been watching Arsenal games h...          0.000000   \n",
       "1  Response 1: Arsenal is doing well, did you cat...          0.844825   \n",
       "2  Response 1: He is a golden retriever, and he's...          0.941946   \n",
       "3  Response 1: I'm planning to take him on long h...          0.000000   \n",
       "4  Response 1: It was a horrible experience and I...          0.000000   \n",
       "5  Response 1: I got scammed by a taxi driver and...          0.000000   \n",
       "6  Response 1: I'm planning to create a special I...          0.000000   \n",
       "7  Response 1: It was a horrible experience. I go...          0.000000   \n",
       "8  Response 1: He is so fun to be with. Im planni...          0.927349   \n",
       "9  Response 1: He brings so much joy to my life. ...          0.938489   \n",
       "\n",
       "   answer_correctness  context_precision  context_recall  \n",
       "0            0.214858                0.0        0.333333  \n",
       "1            0.501332                1.0        0.666667  \n",
       "2            0.427109                1.0        1.000000  \n",
       "3            0.732617                1.0        0.666667  \n",
       "4            0.759290                1.0        1.000000  \n",
       "5            0.213351                1.0        0.333333  \n",
       "6            0.791707                1.0        1.000000  \n",
       "7            0.418789                1.0        0.333333  \n",
       "8            0.887572                1.0        1.000000  \n",
       "9            0.731246                1.0        0.500000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.6 0.4 scores\n",
    "\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_6_4_scores.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "ensemble_hf_6_4 = pd.read_excel(excel_file_path)\n",
    "\n",
    "ensemble_hf_6_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble HF 0.6, 0.4=========================\n",
      "Non-RAG Average Answer Relevancy: 0.36526090687001056\n",
      "Non-RAG Average Answer Correctness: 0.5677870677191184\n",
      "Non-RAG Average Context Precision: 0.89999999991\n",
      "Non-RAG Average Context Recall: 0.6833333333333333\n",
      "=========================Ensemble HF 0.7, 0.3=========================\n",
      "RAG Average Answer Relevancy: 0.6425841014958626\n",
      "RAG Average Answer Correctness: 0.5492757708033762\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7166666666666666\n",
      "=========================Ensemble HF 0.8, 0.2=========================\n",
      "RAG Average Answer Relevancy: 0.36909307640225575\n",
      "RAG Average Answer Correctness: 0.5602780987652676\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate average for 0.6, 0.4\n",
    "rag_ensemble_hf_avg_answer_relevancy_6_4 = ensemble_hf_6_4['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_6_4 = ensemble_hf_6_4['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_6_4 = ensemble_hf_6_4['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_6_4 = ensemble_hf_6_4['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for 0.7, 0.3\n",
    "rag_ensemble_hf_avg_answer_relevancy_7_3 = rag_ensemble_hf_df_7_3['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_7_3 = rag_ensemble_hf_df_7_3['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_7_3 = rag_ensemble_hf_df_7_3['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_7_3 = rag_ensemble_hf_df_7_3['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for 0.8, 0.2\n",
    "rag_ensemble_hf_avg_answer_relevancy_8_2 = rag_ensemble_hf_df_8_2['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_8_2 = rag_ensemble_hf_df_8_2['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_8_2 = rag_ensemble_hf_df_8_2['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_8_2 = rag_ensemble_hf_df_8_2['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble HF 0.6, 0.4=========================\")\n",
    "print(\"Non-RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_6_4)\n",
    "print(\"Non-RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_6_4)\n",
    "print(\"Non-RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_6_4)\n",
    "print(\"Non-RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_6_4)\n",
    "print(\"=========================Ensemble HF 0.7, 0.3=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_7_3)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_7_3)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_7_3)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_7_3)\n",
    "print(\"=========================Ensemble HF 0.8, 0.2=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_8_2)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_8_2)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_8_2)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_8_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_7_3_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_df_7_3.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_8_2_scores.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_hf_df_8_2.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.2.0 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_hf_scores_7_3 = []\n",
    "ensemble_hf_reasons_7_3 = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_ensemble_hf_7_3['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_ensemble_hf_7_3['question'][i],\n",
    "        actual_output=rag_dataset_ensemble_hf_7_3['answer'][i],\n",
    "        expected_output=rag_dataset_ensemble_hf_7_3['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_hf_scores_7_3.append(correctness_metric.score)\n",
    "    ensemble_hf_reasons_7_3.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_hf_scores_8_2 = []\n",
    "ensemble_hf_reasons_8_2 = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_ensemble_hf_8_2['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_ensemble_hf_8_2['question'][i],\n",
    "        actual_output=rag_dataset_ensemble_hf_8_2['answer'][i],\n",
    "        expected_output=rag_dataset_ensemble_hf_8_2['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_hf_scores_8_2.append(correctness_metric.score)\n",
    "    ensemble_hf_reasons_8_2.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.257821</td>\n",
       "      <td>Response 3 in the actual output is similar to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.491448</td>\n",
       "      <td>None of the main content in the actual output ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.915030</td>\n",
       "      <td>The main content of the responses in 'actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>Some main content of the responses generated a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.760092</td>\n",
       "      <td>The main content of the responses in the actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>One of the main content in the actual output, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.645623</td>\n",
       "      <td>The main content of the responses generated in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.620191</td>\n",
       "      <td>The main content of the responses in the actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.944703</td>\n",
       "      <td>The main content of the responses in the actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.757036</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Scores                                            Reasons\n",
       "0           0  0.257821  Response 3 in the actual output is similar to ...\n",
       "1           1  0.491448  None of the main content in the actual output ...\n",
       "2           2  0.915030  The main content of the responses in 'actual o...\n",
       "3           3  0.575091  Some main content of the responses generated a...\n",
       "4           4  0.760092  The main content of the responses in the actua...\n",
       "5           5  0.309339  One of the main content in the actual output, ...\n",
       "6           6  0.645623  The main content of the responses generated in...\n",
       "7           7  0.620191  The main content of the responses in the actua...\n",
       "8           8  0.944703  The main content of the responses in the actua...\n",
       "9           9  0.757036  The main content of the responses in the 'actu..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.6 0.4 scores\n",
    "\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_6_4_v2.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "ensemble_hf_6_4 = pd.read_excel(excel_file_path)\n",
    "\n",
    "ensemble_hf_6_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF 0.6,0.4: 0.6276375029535538\n",
      "Average Score for Ensemble HF 0.7,0.3: 0.6556917153416697\n",
      "Average Score for Ensemble HF 0.8,0.2: 0.610807453001268\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_df_7_3 = pd.DataFrame({'Scores': ensemble_hf_scores_7_3, 'Reasons': ensemble_hf_reasons_7_3})\n",
    "ensemble_hf_df_8_2 = pd.DataFrame({'Scores': ensemble_hf_scores_8_2, 'Reasons': ensemble_hf_reasons_8_2})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf_6_4 = ensemble_hf_6_4['Scores'].mean()\n",
    "ensemble_hf_7_3 = ensemble_hf_df_7_3['Scores'].mean()\n",
    "ensemble_hf_8_2 = ensemble_hf_df_8_2['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF 0.6,0.4:\", ensemble_hf_6_4)\n",
    "print(\"Average Score for Ensemble HF 0.7,0.3:\", ensemble_hf_7_3)\n",
    "print(\"Average Score for Ensemble HF 0.8,0.2:\", ensemble_hf_8_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_7_3_v3.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_7_3.to_excel(excel_file_path)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_8_2_v4.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_8_2.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta filtering and Query altering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"Roydon\": \"Hey there! Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform. Optimistic as always, I see!\"}' metadata={'label': 'Response 1', 'source': 'football.json'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "persona = \"\"\"You would be assisting in identifying topics from a snippet of conversation\"\"\"\n",
    "task = \"\"\"I would supply the conversation directly. Interpret the main topic of the conversation and return the main topic. Do not give multiple topics such as football/soccer. Only give one main topic.\"\"\"\n",
    "example = \"\"\"For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform.\"}\n",
    "\n",
    "           football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            general\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human : {\"Roydon\": \"Yes, I plan to create a special Instagram account just for him! I want to share our adventures and cute moments with everyone.\", \"Xavier\": \"That's a brilliant idea! I'm sure your golden retriever will become an Instagram star in no time. Do you have a name picked out for him yet?\"}\n",
      "\n",
      "pets\n"
     ]
    }
   ],
   "source": [
    "# Construct message object\n",
    "instruction = f\"{persona} {task} {example}\"\n",
    "messages = [SystemMessage(content=instruction)]\n",
    "\n",
    "doc = documents[50]\n",
    "\n",
    "query = doc.page_content\n",
    "\n",
    "print(f\"Human : {query}\\n\")\n",
    "usermsg = HumanMessage(content=query)\n",
    "messages.append(usermsg)\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "# with open('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\pet2.json', 'a') as f:\n",
    "#     json.dump(responses, f, indent=4)\n",
    "#     f.write(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    instruction = f\"{persona} {task} {example}\"\n",
    "    messages = [SystemMessage(content=instruction)]\n",
    "\n",
    "    query = doc.page_content\n",
    "\n",
    "    usermsg = HumanMessage(content=query)\n",
    "    messages.append(usermsg)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    doc.metadata['topic'] = response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'testing_json/documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 48, 59]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[59].metadata['topic'] = 'general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "determination\n",
      "sports\n",
      "football\n",
      "sports\n",
      "football\n",
      "football\n",
      "football\n",
      "football\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "crime\n",
      "problem\n",
      "finances\n",
      "travel\n",
      "emotions\n",
      "ethics\n",
      "experience\n",
      "travel\n",
      "general\n",
      "general\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "pets\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "travel\n",
      "general\n",
      "support\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(doc.metadata['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 48, 59]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x22044968710>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_hugging_face_v3 = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_hugging_face_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_hugging_face_v3.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Filtering Search (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v2 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v2\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: {\"Roydon\": \"Haha, definitely! Looking forward to some intense matches between our teams. Who do you think will be Arsenal's key player this season?\", \"John\": \"I have a feeling Aubameyang will continue to shine for Arsenal. His goals are always a game-changer!\"}\n",
      "football\n"
     ]
    }
   ],
   "source": [
    "# Generate for rag\n",
    "\n",
    "# Learning instructions\n",
    "instruction = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": meta_content,\n",
    "}\n",
    "\n",
    "doc = documents[2]\n",
    "\n",
    "print(\"Query is: \" + doc.page_content)\n",
    "\n",
    "# Initialize messages\n",
    "messages = []\n",
    "\n",
    "# Add learn instruction to message array\n",
    "messages.append(instruction)\n",
    "\n",
    "user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": doc.page_content\n",
    "}\n",
    "\n",
    "messages.append(user_message)\n",
    "\n",
    "openai.api_type = 'openai'\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "raw_response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    ")\n",
    "response_choices = raw_response.choices[0].message.content\n",
    "\n",
    "print(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'topic': 'The main topic of the conversation is football.'}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length is:  1\n",
      "[Document(metadata={'label': 'Response 5', 'source': 'football.json', 'topic': 'football'}, page_content='{\"Roydon\": \"I\\'m optimistic about the new signings, especially Ben White. I think he\\'ll strengthen our defense. How about Manchester United\\'s signings?\", \"John\": \"Varane and Sancho are exciting additions to our squad. Hoping they make a big impact this season. Do you think Arsenal\\'s manager is the right fit for the team?\"}')]\n"
     ]
    }
   ],
   "source": [
    "# Meta filtering retriever to reduce number of documents first\n",
    "new_docs = []\n",
    "\n",
    "new_docs = loaded_faiss_vs_hf_v2.similarity_search(\n",
    "    \"\",\n",
    "    k=10,\n",
    "    filter={\"topic\": response_choices},\n",
    ")\n",
    "\n",
    "print(\"Length is: \", len(new_docs))\n",
    "print(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "retriever_vectordb = loaded_faiss_vs_hf_v2.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v2.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(new_docs)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'label': 'Response 1', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}'), Document(metadata={'label': 'Response 6', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I couldn\\'t agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It\\'s amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}'), Document(metadata={'label': 'Response 1', 'source': 'pet2.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I can\\'t wait to take my new golden retriever dog on long hikes in the mountains!\", \"Xavier\": \"That sounds like a great idea! Golden retrievers love the outdoors. Have you thought about teaching him any tricks?\"}')]\n"
     ]
    }
   ],
   "source": [
    "docs_rel=ensemble_retriever.get_relevant_documents(\"How is your new pet dog?\")\n",
    "docs_rel_top_3 = docs_rel[:3]\n",
    "print(docs_rel_top_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Filtering Search (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v2 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v2\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v2.as_retriever(search_kwargs={\"k\": 6})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  6\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents: [Document(metadata={'label': 'Response 1', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}'), Document(metadata={'label': 'Response 5', 'source': 'pet2.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I\\'m thinking about organizing playdates with other dogs in the neighborhood. It will be a great way for him to socialize and make new friends.\", \"Xavier\": \"That\\'s a fantastic idea! Socializing is important for dogs, and it will also be a great opportunity for you to meet other dog owners. Have you thought about documenting your adventures with your golden retriever?\"}'), Document(metadata={'label': 'Response 6', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I couldn\\'t agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It\\'s amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}'), Document(metadata={'label': 'Response 1', 'source': 'pet2.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I can\\'t wait to take my new golden retriever dog on long hikes in the mountains!\", \"Xavier\": \"That sounds like a great idea! Golden retrievers love the outdoors. Have you thought about teaching him any tricks?\"}'), Document(metadata={'label': 'Response 2', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"It\\'s a golden retriever, and he\\'s the cutest thing ever!\", \"Jacob\": \"Golden retrievers are so friendly and loyal, you\\'re going to have so much fun with him!\"}'), Document(metadata={'label': 'Response 5', 'source': 'pet.json', 'topic': 'pets'}, page_content='{\"Roydon\": \"I feel like my heart is so full having him around, he brings so much joy into my life.\", \"Jacob\": \"Dogs have a way of filling our lives with happiness and love, it\\'s truly a special connection.\"}'), Document(metadata={'label': 'Response 5', 'source': 'football.json'}, page_content='{\"Roydon\": \"I\\'m optimistic about the new signings, especially Ben White. I think he\\'ll strengthen our defense. How about Manchester United\\'s signings?\", \"John\": \"Varane and Sancho are exciting additions to our squad. Hoping they make a big impact this season. Do you think Arsenal\\'s manager is the right fit for the team?\"}'), Document(metadata={'label': 'Response 8', 'source': 'next_trip.json'}, page_content='{\"Roydon\": \"Thank you, Yas! I\\'m grateful for the opportunity to experience Japan and create new memories that will last a lifetime.\", \"Yas\": \"Cherish every moment and embrace the journey with open arms. Japan is about to become your new favorite destination!\"}'), Document(metadata={'label': 'Response 6', 'source': 'football.json'}, page_content='{\"Roydon\": \"Arteta has been making some good decisions lately, so I have faith in him. How about Ole Gunnar Solskjaer?\", \"John\": \"Solskjaer has been improving as a manager, but there\\'s still room for growth. It\\'ll be interesting to see how both managers perform this season. What\\'s your prediction for Arsenal\\'s first match?\"}'), Document(metadata={'label': 'Response 4', 'source': 'football.json'}, page_content='{\"Roydon\": \"I couldn\\'t agree more! Aubameyang is a true asset to the team. Do you think Arsenal will make it to the top four this season?\", \"John\": \"It\\'s definitely possible with the right strategy and teamwork. What are your thoughts on Arsenal\\'s new signings?\"}')]\n",
      "Number of relevant documents: 10\n"
     ]
    }
   ],
   "source": [
    "query = \"How is your new pet dog?\"\n",
    "\n",
    "try:\n",
    "    docs_rel = ensemble_retriever.invoke(query)\n",
    "    print(\"Retrieved documents:\", docs_rel)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# docs_rel_top_3 = docs_rel\n",
    "print(\"Number of relevant documents:\", len(docs_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How is your new pet dog?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "docs_rel_top_3 = docs_rel\n",
    "len(docs_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: How is your new pet dog?\n",
      "pets\n"
     ]
    }
   ],
   "source": [
    "# Generate for rag\n",
    "\n",
    "# Learning instructions\n",
    "instruction = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": meta_content,\n",
    "}\n",
    "\n",
    "print(\"Query is: \" + query)\n",
    "\n",
    "# Initialize messages\n",
    "messages = []\n",
    "\n",
    "# Add learn instruction to message array\n",
    "messages.append(instruction)\n",
    "\n",
    "user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "}\n",
    "\n",
    "messages.append(user_message)\n",
    "\n",
    "openai.api_type = 'openai'\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "raw_response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    ")\n",
    "topic = raw_response.choices[0].message.content\n",
    "\n",
    "print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Filter according to the topic\n",
    "filtered_docs = []\n",
    "\n",
    "for doc in docs_rel:\n",
    "    if(doc.metadata['topic'] == topic):\n",
    "        filtered_docs.append(doc)\n",
    "\n",
    "print(len(filtered_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That's awesome! What breed is it?\"}' metadata={'label': 'Response 1', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I'm thinking about organizing playdates with other dogs in the neighborhood. It will be a great way for him to socialize and make new friends.\", \"Xavier\": \"That's a fantastic idea! Socializing is important for dogs, and it will also be a great opportunity for you to meet other dog owners. Have you thought about documenting your adventures with your golden retriever?\"}' metadata={'label': 'Response 5', 'source': 'pet2.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I couldn't agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It's amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}' metadata={'label': 'Response 6', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I can't wait to take my new golden retriever dog on long hikes in the mountains!\", \"Xavier\": \"That sounds like a great idea! Golden retrievers love the outdoors. Have you thought about teaching him any tricks?\"}' metadata={'label': 'Response 1', 'source': 'pet2.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"It's a golden retriever, and he's the cutest thing ever!\", \"Jacob\": \"Golden retrievers are so friendly and loyal, you're going to have so much fun with him!\"}' metadata={'label': 'Response 2', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I feel like my heart is so full having him around, he brings so much joy into my life.\", \"Jacob\": \"Dogs have a way of filling our lives with happiness and love, it's truly a special connection.\"}' metadata={'label': 'Response 5', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I'm optimistic about the new signings, especially Ben White. I think he'll strengthen our defense. How about Manchester United's signings?\", \"John\": \"Varane and Sancho are exciting additions to our squad. Hoping they make a big impact this season. Do you think Arsenal's manager is the right fit for the team?\"}' metadata={'label': 'Response 5', 'source': 'football.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"Thank you, Yas! I'm grateful for the opportunity to experience Japan and create new memories that will last a lifetime.\", \"Yas\": \"Cherish every moment and embrace the journey with open arms. Japan is about to become your new favorite destination!\"}' metadata={'label': 'Response 8', 'source': 'next_trip.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"Arteta has been making some good decisions lately, so I have faith in him. How about Ole Gunnar Solskjaer?\", \"John\": \"Solskjaer has been improving as a manager, but there's still room for growth. It'll be interesting to see how both managers perform this season. What's your prediction for Arsenal's first match?\"}' metadata={'label': 'Response 6', 'source': 'football.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"I couldn't agree more! Aubameyang is a true asset to the team. Do you think Arsenal will make it to the top four this season?\", \"John\": \"It's definitely possible with the right strategy and teamwork. What are your thoughts on Arsenal's new signings?\"}' metadata={'label': 'Response 4', 'source': 'football.json', 'topic': 'football'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs_rel:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That's awesome! What breed is it?\"}' metadata={'label': 'Response 1', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I'm thinking about organizing playdates with other dogs in the neighborhood. It will be a great way for him to socialize and make new friends.\", \"Xavier\": \"That's a fantastic idea! Socializing is important for dogs, and it will also be a great opportunity for you to meet other dog owners. Have you thought about documenting your adventures with your golden retriever?\"}' metadata={'label': 'Response 5', 'source': 'pet2.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I couldn't agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It's amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}' metadata={'label': 'Response 6', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I can't wait to take my new golden retriever dog on long hikes in the mountains!\", \"Xavier\": \"That sounds like a great idea! Golden retrievers love the outdoors. Have you thought about teaching him any tricks?\"}' metadata={'label': 'Response 1', 'source': 'pet2.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"It's a golden retriever, and he's the cutest thing ever!\", \"Jacob\": \"Golden retrievers are so friendly and loyal, you're going to have so much fun with him!\"}' metadata={'label': 'Response 2', 'source': 'pet.json', 'topic': 'pets'}\n",
      "page_content='{\"Roydon\": \"I feel like my heart is so full having him around, he brings so much joy into my life.\", \"Jacob\": \"Dogs have a way of filling our lives with happiness and love, it's truly a special connection.\"}' metadata={'label': 'Response 5', 'source': 'pet.json', 'topic': 'pets'}\n"
     ]
    }
   ],
   "source": [
    "for docs in filtered_docs:\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand and any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v3 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v3\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# documents = []\n",
    "# for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\'):\n",
    "#     if filename.endswith(\".json\"):\n",
    "#         with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\{filename}') as f:\n",
    "#             data = json.load(f)\n",
    "#             for response_label, conversation in data.items():\n",
    "#                 doc_content = json.dumps(conversation)\n",
    "#                 doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "#                 documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "# print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 61 documents.\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\documents.json'\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    documents_json = json.load(json_file)\n",
    "\n",
    "# Convert the JSON serializable format back to Document objects\n",
    "documents = [\n",
    "    Document(page_content=doc['page_content'], metadata=doc['metadata'])\n",
    "    for doc in documents_json\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v3.as_retriever(search_kwargs={\"k\": 6})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  6\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate meta content\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple topic\n"
     ]
    }
   ],
   "source": [
    "import inflect\n",
    "\n",
    "def singularize_and_lower(topic):\n",
    "    # Create an inflect engine for handling plurals\n",
    "    engine = inflect.engine()\n",
    "    \n",
    "    # Lowercase the topic\n",
    "    topic = topic.lower()\n",
    "    \n",
    "    # Singularize the topic (convert plurals to singular), returns false if not noun\n",
    "    topic = engine.singular_noun(topic) if engine.singular_noun(topic) else topic\n",
    "    \n",
    "    return topic\n",
    "\n",
    "print(singularize_and_lower(\"multiple topics\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Instead of inflect use lemmatization for noun\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def is_valid_word(word):\n",
    "    \"\"\"Check if a word is valid by looking it up in WordNet.\"\"\"\n",
    "    return bool(wordnet.synsets(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts.\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def remove_ing(topic):\n",
    "    if topic.endswith('ing'):\n",
    "        return topic[:-3]\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def singularize_and_lower_lemmatize(topic):\n",
    "    # Initialize the WordNet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lowercase the topic\n",
    "    topic = topic.lower()\n",
    "\n",
    "    # Lemmatize the word with correct POS tag\n",
    "    pos = get_wordnet_pos(topic)\n",
    "    topic_lemmataized = lemmatizer.lemmatize(topic, pos)\n",
    "\n",
    "    # Extra check for words like crotcheting\n",
    "    topic = remove_ing(topic_lemmataized)\n",
    "    processed_words = [is_valid_word(word) for word in topic.split()]\n",
    "    if not all(processed_words):\n",
    "        return topic_lemmataized\n",
    "        \n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lematization results:  crotchet\n",
      "inflect results:  crotcheting\n"
     ]
    }
   ],
   "source": [
    "print(\"lematization results: \", singularize_and_lower_lemmatize(\"crotcheting\"))\n",
    "print(\"inflect results: \", singularize_and_lower(\"crotcheting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lematization results:  giant animals\n",
      "inflect results:  giant animal\n"
     ]
    }
   ],
   "source": [
    "print(\"lematization results: \", singularize_and_lower_lemmatize(\"giant animals\"))\n",
    "print(\"inflect results: \", singularize_and_lower(\"giant animals\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lematization results:  fly\n",
      "inflect results:  flying\n"
     ]
    }
   ],
   "source": [
    "print(\"lematization results: \", singularize_and_lower_lemmatize(\"flying\"))\n",
    "print(\"inflect results: \", singularize_and_lower(\"flying\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lematization results:  crotchet\n",
      "inflect results:  crotchet\n"
     ]
    }
   ],
   "source": [
    "print(\"lematization results: \", singularize_and_lower_lemmatize(\"crotchets\"))\n",
    "print(\"inflect results: \", singularize_and_lower(\"crotchets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def filter_list(docs_rel, topic):\n",
    "    # Filter according to the topic\n",
    "    filtered_docs = []\n",
    "    final_docs = []\n",
    "    general_topic = {}\n",
    "\n",
    "    if singularize_and_lower(topic) == \"general\":\n",
    "        for doc in docs_rel:\n",
    "            if singularize_and_lower(doc.metadata['topic']) not in general_topic:\n",
    "                general_topic[singularize_and_lower(doc.metadata['topic'])] = 1\n",
    "                filtered_docs.append(doc)\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for doc in docs_rel:\n",
    "            if(singularize_and_lower(doc.metadata['topic']) == singularize_and_lower(topic)):\n",
    "                filtered_docs.append(doc)\n",
    "       \n",
    "    if len(filtered_docs) > 2:\n",
    "        final_docs = filtered_docs[:3]\n",
    "        return final_docs\n",
    "    else:\n",
    "        count = 3 - len(filtered_docs)\n",
    "        final_docs = filtered_docs\n",
    "        position = 0\n",
    "        for i in range(count):\n",
    "            if(position == len(docs_rel)):\n",
    "                break\n",
    "            if(docs_rel[position] in filtered_docs):\n",
    "                i = i-1\n",
    "                position += 1\n",
    "                continue\n",
    "            else:\n",
    "                final_docs.append(docs_rel[position])# need to change so that it wont be same obtained\n",
    "                position+=1 \n",
    "        \n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: What have you been up to Roydon?\n",
      "page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}' metadata={'label': 'Response 3', 'source': 'travel.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn't they?\"}' metadata={'label': 'Response 1', 'source': 'football2.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"Easy for you to say. You weren't the one stuck in a foreign country with nothing going right.\", \"Dory\": \"I know, but sometimes these things happen. You just have to try and make the best of it.\"}' metadata={'label': 'Response 7', 'source': 'travel.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"I can't believe what happened to me in Thailand.\", \"Xavier\": \"What happened?\"}' metadata={'label': 'Response 1', 'source': 'next_trip2.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"Not yet, but I'm thinking of visiting Tokyo, Kyoto, and Osaka. I want to experience both the bustling city life and the serene countryside.\", \"Yas\": \"That sounds like a perfect balance! I'm sure you'll have a fantastic time exploring all those places.\"}' metadata={'label': 'Response 3', 'source': 'next_trip.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"Hey there! Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform. Optimistic as always, I see!\"}' metadata={'label': 'Response 1', 'source': 'football.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"No, I had to borrow money from a friend to get back home.\", \"Xavier\": \"That must have been a really stressful experience.\"}' metadata={'label': 'Response 4', 'source': 'next_trip2.json', 'topic': 'general'}\n",
      "page_content='{\"Roydon\": \"Arteta has been making some good decisions lately, so I have faith in him. How about Ole Gunnar Solskjaer?\", \"John\": \"Solskjaer has been improving as a manager, but there's still room for growth. It'll be interesting to see how both managers perform this season. What's your prediction for Arsenal's first match?\"}' metadata={'label': 'Response 6', 'source': 'football.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"Absolutely! Gotta stay positive, right? What team do you support?\", \"John\": \"I'm a Manchester United fan, so we might have some friendly rivalry this season!\"}' metadata={'label': 'Response 2', 'source': 'football.json', 'topic': 'football'}\n",
      "page_content='{\"Roydon\": \"Hey Yas, I'm still fuming about my terrible experience in Thailand, but you know what? I'm super excited about my upcoming trip to Japan!\", \"Yas\": \"Oh no, what happened in Thailand? But that's great to hear about Japan! What are you looking forward to the most?\"}' metadata={'label': 'Response 1', 'source': 'next_trip.json', 'topic': 'travel'}\n",
      "page_content='{\"Roydon\": \"I'm thinking of naming him Sunny, because he brings so much joy and sunshine into my life. What do you think?\", \"Xavier\": \"Sunny is a perfect name for a golden retriever! It suits his happy and cheerful personality. I can't wait to see all the fun adventures you two will have together.\"}' metadata={'label': 'Response 7', 'source': 'pet2.json', 'topic': 'pets'}\n",
      "Topic is:  general\n"
     ]
    }
   ],
   "source": [
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "topic_interpreted = getTopic(meta_content, query)\n",
    "for i in (docs_rel):\n",
    "    print(i)\n",
    "\n",
    "print(\"Topic is: \", topic_interpreted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[Document(metadata={'label': 'Response 3', 'source': 'travel.json', 'topic': 'travel'}, page_content='{\"Roydon\": \"I tried to, but everywhere I went, I just kept getting ripped off by the locals.\", \"Dory\": \"That must have been frustrating. Did you try any of the street food at least?\"}'), Document(metadata={'label': 'Response 1', 'source': 'football2.json', 'topic': 'football'}, page_content='{\"Roydon\": \"Hey there! Did you catch the Arsenal game last night? What a thrilling match!\", \"John\": \"Hey Roydon! Yes, I watched it. Arsenal played really well, didn\\'t they?\"}')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the filter_list function\n",
    "query = \"What have you been up to Roydon?\"\n",
    "docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "test_docs = []\n",
    "test_docs.append(docs_rel[0])\n",
    "test_docs.append(docs_rel[1])\n",
    "\n",
    "final_docs = filter_list(test_docs, \"general\")\n",
    "\n",
    "print(len(final_docs))\n",
    "print(final_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    \n",
    "    topic_interpreted = getTopic(meta_content, query)\n",
    "    \n",
    "    final_docs = filter_list(docs_rel, topic_interpreted) # Still top 3\n",
    "\n",
    "    contexts = \"\"\n",
    "    for context in final_docs:\n",
    "        contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path (v1 is before the changed filtered list)\n",
    "file_path = 'testing_json/Improve_RAG/meta_filter_v2.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAGAS And G-Eval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# RAGAS \n",
    "file_path_meta_filter = 'testing_json/Improve_RAG/meta_filter_v2.json'\n",
    "\n",
    "with open(file_path_meta_filter, 'r') as json_file:\n",
    "    rag_ensemble_meta_filter = json.load(json_file)\n",
    "\n",
    "rag_dataset_meta_filter = Dataset.from_dict(rag_ensemble_meta_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "rag_dataset_ensemble_meta_filter_score = evaluate(rag_dataset_meta_filter, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_ensemble_meta_filter_df = rag_dataset_ensemble_meta_filter_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What have you been up to Roydon?</td>\n",
       "      <td>Response 1: I tried to, but everywhere I went,...</td>\n",
       "      <td>['{\"Roydon\": \"I tried to, but everywhere I wen...</td>\n",
       "      <td>Response 1: I've been watching Arsenal games h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Woah really how is Arsenal doing right now then?</td>\n",
       "      <td>Response 1: Arsenal is currently showing great...</td>\n",
       "      <td>['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...</td>\n",
       "      <td>Response 1: Arsenal is doing well, did you cat...</td>\n",
       "      <td>0.902912</td>\n",
       "      <td>0.980656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice what breed is your new pet dog?</td>\n",
       "      <td>Response 1: It's a golden retriever, and he's ...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>0.956775</td>\n",
       "      <td>0.612637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>So what you planning to do with your pet dog?</td>\n",
       "      <td>Response 1: I'm planning to teach him how to f...</td>\n",
       "      <td>['{\"Roydon\": \"Absolutely! I\\'m planning to tea...</td>\n",
       "      <td>Response 1: I'm planning to take him on long h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How was your trip to thailand?</td>\n",
       "      <td>Response 1: It didn't go as planned, but I'm l...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe how terrible my...</td>\n",
       "      <td>Response 1: It was a horrible experience and I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What happened in thailand?</td>\n",
       "      <td>Response 1: My hotel reservation got messed up...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe what happened t...</td>\n",
       "      <td>Response 1: I got scammed by a taxi driver and...</td>\n",
       "      <td>0.911640</td>\n",
       "      <td>0.231538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What channel are you planning to create for yo...</td>\n",
       "      <td>Response 1: I'm thinking of creating an Instag...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to create a special I...</td>\n",
       "      <td>0.886203</td>\n",
       "      <td>0.220141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How was your trip to thailand and any new trav...</td>\n",
       "      <td>Response 1: Thailand was a rollercoaster of mi...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t wait to immerse myself ...</td>\n",
       "      <td>Response 1: It was a horrible experience. I go...</td>\n",
       "      <td>0.922883</td>\n",
       "      <td>0.369110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>I heard you got a new pet dog how is he? What ...</td>\n",
       "      <td>Response 1: He's doing great! I named him Sunn...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is so fun to be with. Im planni...</td>\n",
       "      <td>0.911895</td>\n",
       "      <td>0.981487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hows your new pet dog? What breed is he?</td>\n",
       "      <td>Response 1: He's a golden retriever, and he's ...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He brings so much joy to my life. ...</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>0.457522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                   What have you been up to Roydon?   \n",
       "1           1   Woah really how is Arsenal doing right now then?   \n",
       "2           2               Nice what breed is your new pet dog?   \n",
       "3           3      So what you planning to do with your pet dog?   \n",
       "4           4                     How was your trip to thailand?   \n",
       "5           5                         What happened in thailand?   \n",
       "6           6  What channel are you planning to create for yo...   \n",
       "7           7  How was your trip to thailand and any new trav...   \n",
       "8           8  I heard you got a new pet dog how is he? What ...   \n",
       "9           9           Hows your new pet dog? What breed is he?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Response 1: I tried to, but everywhere I went,...   \n",
       "1  Response 1: Arsenal is currently showing great...   \n",
       "2  Response 1: It's a golden retriever, and he's ...   \n",
       "3  Response 1: I'm planning to teach him how to f...   \n",
       "4  Response 1: It didn't go as planned, but I'm l...   \n",
       "5  Response 1: My hotel reservation got messed up...   \n",
       "6  Response 1: I'm thinking of creating an Instag...   \n",
       "7  Response 1: Thailand was a rollercoaster of mi...   \n",
       "8  Response 1: He's doing great! I named him Sunn...   \n",
       "9  Response 1: He's a golden retriever, and he's ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['{\"Roydon\": \"I tried to, but everywhere I wen...   \n",
       "1  ['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...   \n",
       "2  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "3  ['{\"Roydon\": \"Absolutely! I\\'m planning to tea...   \n",
       "4  ['{\"Roydon\": \"I can\\'t believe how terrible my...   \n",
       "5  ['{\"Roydon\": \"I can\\'t believe what happened t...   \n",
       "6  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "7  ['{\"Roydon\": \"I can\\'t wait to immerse myself ...   \n",
       "8  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "9  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Response 1: I've been watching Arsenal games h...          0.000000   \n",
       "1  Response 1: Arsenal is doing well, did you cat...          0.902912   \n",
       "2  Response 1: He is a golden retriever, and he's...          0.956775   \n",
       "3  Response 1: I'm planning to take him on long h...          0.000000   \n",
       "4  Response 1: It was a horrible experience and I...          0.000000   \n",
       "5  Response 1: I got scammed by a taxi driver and...          0.911640   \n",
       "6  Response 1: I'm planning to create a special I...          0.886203   \n",
       "7  Response 1: It was a horrible experience. I go...          0.922883   \n",
       "8  Response 1: He is so fun to be with. Im planni...          0.911895   \n",
       "9  Response 1: He brings so much joy to my life. ...          0.933533   \n",
       "\n",
       "   answer_correctness  context_precision  context_recall  \n",
       "0            0.214522                0.0        0.333333  \n",
       "1            0.980656                1.0        0.666667  \n",
       "2            0.612637                1.0        1.000000  \n",
       "3            0.768200                1.0        0.666667  \n",
       "4            0.656944                1.0        1.000000  \n",
       "5            0.231538                1.0        0.333333  \n",
       "6            0.220141                1.0        1.000000  \n",
       "7            0.369110                1.0        0.666667  \n",
       "8            0.981487                1.0        1.000000  \n",
       "9            0.457522                1.0        0.500000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.7 0.3 scores\n",
    "\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_hf_7_3_scores.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "ensemble_hf_7_3 = pd.read_excel(excel_file_path)\n",
    "\n",
    "ensemble_hf_7_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble HF 0.7, 0.3=========================\n",
      "RAG Average Answer Relevancy: 0.6425841014958626\n",
      "RAG Average Answer Correctness: 0.5492757708033762\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7166666666666666\n",
      "=========================Ensemble Meta Filtered=========================\n",
      "RAG Average Answer Relevancy: 0.46346294017261014\n",
      "RAG Average Answer Correctness: 0.48074996223308925\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Calculate average for 0.7, 0.3\n",
    "rag_ensemble_hf_avg_answer_relevancy_7_3 = ensemble_hf_7_3['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_7_3 = ensemble_hf_7_3['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_7_3 = ensemble_hf_7_3['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_7_3 = ensemble_hf_7_3['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for meta_filtered\n",
    "rag_ensemble_meta_filter_avg_answer_relevancy = rag_ensemble_meta_filter_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_answer_correctness = rag_ensemble_meta_filter_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_precision = rag_ensemble_meta_filter_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_recall = rag_ensemble_meta_filter_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble HF 0.7, 0.3=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_7_3)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_7_3)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_7_3)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_7_3)\n",
    "print(\"=========================Ensemble Meta Filtered=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_meta_filter_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_meta_filter_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_meta_filter_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_meta_filter_avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble HF 0.7, 0.3=========================\n",
      "RAG Average Answer Relevancy: 0.6425841014958626\n",
      "RAG Average Answer Correctness: 0.5492757708033762\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7166666666666666\n",
      "=========================Ensemble Meta Filtered=========================\n",
      "RAG Average Answer Relevancy: 0.6723204037179018\n",
      "RAG Average Answer Correctness: 0.568161100684651\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Version 2 (With filtered function)\n",
    "\n",
    "# Calculate average for 0.7, 0.3\n",
    "rag_ensemble_hf_avg_answer_relevancy_7_3 = ensemble_hf_7_3['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_answer_correctness_7_3 = ensemble_hf_7_3['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_precision_7_3 = ensemble_hf_7_3['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_hf_avg_recall_7_3 = ensemble_hf_7_3['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for meta_filtered\n",
    "rag_ensemble_meta_filter_avg_answer_relevancy = combined['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_answer_correctness = combined['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_precision = combined['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_recall = combined['context_recall'].mean(skipna=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble HF 0.7, 0.3=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_hf_avg_answer_relevancy_7_3)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_hf_avg_answer_correctness_7_3)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_hf_avg_precision_7_3)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_hf_avg_recall_7_3)\n",
    "print(\"=========================Ensemble Meta Filtered=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_meta_filter_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_meta_filter_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_meta_filter_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_meta_filter_avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_meta_filter_scores_v3.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_meta_filter_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.2.4 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_meta_filter_scores = []\n",
    "ensemble_meta_filter_reasons = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_meta_filter['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_meta_filter['question'][i],\n",
    "        actual_output=rag_dataset_meta_filter['answer'][i],\n",
    "        expected_output=rag_dataset_meta_filter['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_meta_filter_scores.append(correctness_metric.score)\n",
    "    ensemble_meta_filter_reasons.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.280397</td>\n",
       "      <td>Response 1 in Actual Output does not match any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>The main content of the responses in the 'Actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799122</td>\n",
       "      <td>The main content of all responses in 'actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>Main content of responses in 'actual output' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>Two out of three responses in the actual outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.253476</td>\n",
       "      <td>The main content of the responses in the actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.624999</td>\n",
       "      <td>One of the main content of the responses (crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.585437</td>\n",
       "      <td>Two responses in the actual output match close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.870620</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.829752</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Scores                                            Reasons\n",
       "0           0  0.280397  Response 1 in Actual Output does not match any...\n",
       "1           1  0.535548  The main content of the responses in the 'Actu...\n",
       "2           2  0.799122  The main content of all responses in 'actual o...\n",
       "3           3  0.586623  Main content of responses in 'actual output' a...\n",
       "4           4  0.742100  Two out of three responses in the actual outpu...\n",
       "5           5  0.253476  The main content of the responses in the actua...\n",
       "6           6  0.624999  One of the main content of the responses (crea...\n",
       "7           7  0.585437  Two responses in the actual output match close...\n",
       "8           8  0.870620  The main content of the responses in the 'actu...\n",
       "9           9  0.829752  The main content of the responses in the 'actu..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.6 0.4 scores\n",
    "\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_hf_7_3_v3.xlsx' # Change to 7,3\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "ensemble_hf_7_3 = pd.read_excel(excel_file_path)\n",
    "\n",
    "ensemble_hf_7_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF 0.7,0.3: 0.6556917153416697\n",
      "Average Score for Ensemble HF Meta Filtered: 0.6632734878019907\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_df_meta_filter = pd.DataFrame({'Scores': ensemble_meta_filter_scores, 'Reasons': ensemble_meta_filter_reasons})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf_7_3 = ensemble_hf_7_3['Scores'].mean()\n",
    "ensemble_hf_meta_filter = ensemble_hf_df_meta_filter['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF 0.7,0.3:\", ensemble_hf_7_3)\n",
    "print(\"Average Score for Ensemble HF Meta Filtered:\", ensemble_hf_meta_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF 0.7,0.3: 0.6556917153416697\n",
      "Average Score for Ensemble HF Meta Filtered: 0.6873390817852749\n"
     ]
    }
   ],
   "source": [
    "# VERSION 2 (With the new filter_list function)\n",
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_df_meta_filter = pd.DataFrame({'Scores': ensemble_meta_filter_scores, 'Reasons': ensemble_meta_filter_reasons})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf_7_3 = ensemble_hf_7_3['Scores'].mean()\n",
    "ensemble_hf_meta_filter = ensemble_hf_df_meta_filter['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF 0.7,0.3:\", ensemble_hf_7_3)\n",
    "print(\"Average Score for Ensemble HF Meta Filtered:\", ensemble_hf_meta_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_meta_filtered_v2.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_meta_filter.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's always exciting to see how your team will perform.\"}\n",
    "\n",
    "            Topic is football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            Topic is travel.\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            Topic is general. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: {\"Roydon\": \"Haha, definitely! Looking forward to some intense matches between our teams. Who do you think will be Arsenal's key player this season?\", \"John\": \"I have a feeling Aubameyang will continue to shine for Arsenal. His goals are always a game-changer!\"}\n",
      "Topic is football\n"
     ]
    }
   ],
   "source": [
    "# Generate for rag\n",
    "\n",
    "# Learning instructions\n",
    "instruction = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": content,\n",
    "}\n",
    "\n",
    "doc = documents[2]\n",
    "\n",
    "print(\"Query is: \" + doc.page_content)\n",
    "\n",
    "# Initialize messages\n",
    "messages = []\n",
    "\n",
    "# Add learn instruction to message array\n",
    "messages.append(instruction)\n",
    "\n",
    "user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": doc.page_content\n",
    "}\n",
    "\n",
    "messages.append(user_message)\n",
    "\n",
    "openai.api_type = 'openai'\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "raw_response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    ")\n",
    "response_choices = raw_response.choices[0].message.content\n",
    "\n",
    "print(response_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Altering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB 131.3 kB/s eta 0:00:12\n",
      "                                              0.0/1.5 MB 131.3 kB/s eta 0:00:12\n",
      "                                              0.0/1.5 MB 131.3 kB/s eta 0:00:12\n",
      "                                              0.0/1.5 MB 131.3 kB/s eta 0:00:12\n",
      "     -                                        0.0/1.5 MB 93.7 kB/s eta 0:00:16\n",
      "     -                                        0.0/1.5 MB 93.7 kB/s eta 0:00:16\n",
      "     -                                        0.0/1.5 MB 93.7 kB/s eta 0:00:16\n",
      "     -                                        0.1/1.5 MB 109.2 kB/s eta 0:00:14\n",
      "     -                                        0.1/1.5 MB 109.2 kB/s eta 0:00:14\n",
      "     -                                        0.1/1.5 MB 109.2 kB/s eta 0:00:14\n",
      "     -                                        0.1/1.5 MB 109.2 kB/s eta 0:00:14\n",
      "     -                                        0.1/1.5 MB 109.2 kB/s eta 0:00:14\n",
      "     -                                        0.1/1.5 MB 91.4 kB/s eta 0:00:16\n",
      "     -                                        0.1/1.5 MB 91.4 kB/s eta 0:00:16\n",
      "     -                                        0.1/1.5 MB 91.4 kB/s eta 0:00:16\n",
      "     -                                        0.1/1.5 MB 91.4 kB/s eta 0:00:16\n",
      "     --                                       0.1/1.5 MB 95.4 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.4 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.4 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.4 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.4 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.0 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.0 kB/s eta 0:00:15\n",
      "     --                                       0.1/1.5 MB 95.0 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 93.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 91.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 91.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 91.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 91.6 kB/s eta 0:00:15\n",
      "     ---                                      0.1/1.5 MB 91.6 kB/s eta 0:00:15\n",
      "     ----                                     0.2/1.5 MB 85.7 kB/s eta 0:00:16\n",
      "     ----                                     0.2/1.5 MB 85.7 kB/s eta 0:00:16\n",
      "     ----                                     0.2/1.5 MB 85.7 kB/s eta 0:00:16\n",
      "     ----                                     0.2/1.5 MB 85.7 kB/s eta 0:00:16\n",
      "     ----                                     0.2/1.5 MB 88.8 kB/s eta 0:00:15\n",
      "     ----                                     0.2/1.5 MB 88.8 kB/s eta 0:00:15\n",
      "     ----                                     0.2/1.5 MB 88.8 kB/s eta 0:00:15\n",
      "     -----                                    0.2/1.5 MB 92.2 kB/s eta 0:00:15\n",
      "     -----                                    0.2/1.5 MB 92.2 kB/s eta 0:00:15\n",
      "     -----                                    0.2/1.5 MB 92.2 kB/s eta 0:00:15\n",
      "     -----                                    0.2/1.5 MB 92.9 kB/s eta 0:00:14\n",
      "     -----                                    0.2/1.5 MB 92.9 kB/s eta 0:00:14\n",
      "     -----                                    0.2/1.5 MB 92.9 kB/s eta 0:00:14\n",
      "     -----                                    0.2/1.5 MB 96.9 kB/s eta 0:00:14\n",
      "     -----                                    0.2/1.5 MB 96.9 kB/s eta 0:00:14\n",
      "     -----                                    0.2/1.5 MB 96.9 kB/s eta 0:00:14\n",
      "     ------                                   0.2/1.5 MB 96.8 kB/s eta 0:00:14\n",
      "     ------                                   0.2/1.5 MB 96.8 kB/s eta 0:00:14\n",
      "     ------                                   0.2/1.5 MB 96.8 kB/s eta 0:00:14\n",
      "     ------                                   0.3/1.5 MB 98.9 kB/s eta 0:00:13\n",
      "     ------                                   0.3/1.5 MB 98.9 kB/s eta 0:00:13\n",
      "     ------                                   0.3/1.5 MB 98.9 kB/s eta 0:00:13\n",
      "     ------                                   0.3/1.5 MB 98.9 kB/s eta 0:00:13\n",
      "     -------                                  0.3/1.5 MB 99.6 kB/s eta 0:00:13\n",
      "     -------                                  0.3/1.5 MB 99.6 kB/s eta 0:00:13\n",
      "     -------                                  0.3/1.5 MB 99.6 kB/s eta 0:00:13\n",
      "     -------                                  0.3/1.5 MB 98.8 kB/s eta 0:00:13\n",
      "     -------                                  0.3/1.5 MB 98.8 kB/s eta 0:00:13\n",
      "     --------                                 0.3/1.5 MB 101.6 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 101.6 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 101.6 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 101.6 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 99.8 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 99.8 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 99.8 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 99.8 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 99.8 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     --------                                 0.3/1.5 MB 98.5 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 97.7 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 97.7 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 97.7 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 96.8 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 96.8 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 96.8 kB/s eta 0:00:12\n",
      "     ---------                                0.4/1.5 MB 96.8 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 97.4 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 97.4 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 97.4 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 96.9 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 96.9 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 96.9 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 96.9 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 96.9 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 94.3 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 94.3 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 94.3 kB/s eta 0:00:12\n",
      "     ----------                               0.4/1.5 MB 94.3 kB/s eta 0:00:12\n",
      "     -----------                              0.4/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.4/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.4/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.4/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.4/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.5/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.5/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     -----------                              0.5/1.5 MB 94.9 kB/s eta 0:00:12\n",
      "     ------------                             0.5/1.5 MB 94.6 kB/s eta 0:00:12\n",
      "     ------------                             0.5/1.5 MB 94.6 kB/s eta 0:00:12\n",
      "     ------------                             0.5/1.5 MB 96.9 kB/s eta 0:00:11\n",
      "     ------------                             0.5/1.5 MB 96.9 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 96.9 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 96.9 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 96.9 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 98.5 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 98.5 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 98.5 kB/s eta 0:00:11\n",
      "     -------------                            0.5/1.5 MB 98.5 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 99.5 kB/s eta 0:00:10\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.5/1.5 MB 96.3 kB/s eta 0:00:11\n",
      "     --------------                           0.6/1.5 MB 95.7 kB/s eta 0:00:10\n",
      "     --------------                           0.6/1.5 MB 95.7 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 95.6 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 95.6 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 95.6 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 95.6 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 96.5 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 96.5 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 96.5 kB/s eta 0:00:10\n",
      "     ---------------                          0.6/1.5 MB 96.5 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 97.4 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 97.4 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 97.4 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 96.2 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 96.2 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 96.2 kB/s eta 0:00:10\n",
      "     ----------------                         0.6/1.5 MB 96.2 kB/s eta 0:00:10\n",
      "     -----------------                        0.6/1.5 MB 97.0 kB/s eta 0:00:09\n",
      "     -----------------                        0.6/1.5 MB 97.0 kB/s eta 0:00:09\n",
      "     -----------------                        0.6/1.5 MB 97.0 kB/s eta 0:00:09\n",
      "     -----------------                        0.6/1.5 MB 97.0 kB/s eta 0:00:09\n",
      "     -----------------                        0.6/1.5 MB 97.0 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.8 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.8 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.8 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.8 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.8 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.7 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.7 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.7 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.7 kB/s eta 0:00:09\n",
      "     -----------------                        0.7/1.5 MB 95.7 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 95.5 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 95.5 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 95.5 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 95.5 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 95.5 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     ------------------                       0.7/1.5 MB 94.4 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 92.7 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 92.7 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 92.7 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 92.7 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 91.6 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 91.6 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 91.6 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 91.6 kB/s eta 0:00:09\n",
      "     -------------------                      0.7/1.5 MB 91.6 kB/s eta 0:00:09\n",
      "     --------------------                     0.8/1.5 MB 92.0 kB/s eta 0:00:09\n",
      "     --------------------                     0.8/1.5 MB 92.0 kB/s eta 0:00:09\n",
      "     --------------------                     0.8/1.5 MB 92.0 kB/s eta 0:00:09\n",
      "     --------------------                     0.8/1.5 MB 93.1 kB/s eta 0:00:08\n",
      "     --------------------                     0.8/1.5 MB 93.1 kB/s eta 0:00:08\n",
      "     --------------------                     0.8/1.5 MB 93.3 kB/s eta 0:00:08\n",
      "     --------------------                     0.8/1.5 MB 93.3 kB/s eta 0:00:08\n",
      "     --------------------                     0.8/1.5 MB 93.3 kB/s eta 0:00:08\n",
      "     --------------------                     0.8/1.5 MB 93.3 kB/s eta 0:00:08\n",
      "     ---------------------                    0.8/1.5 MB 93.8 kB/s eta 0:00:08\n",
      "     ---------------------                    0.8/1.5 MB 94.5 kB/s eta 0:00:08\n",
      "     ---------------------                    0.8/1.5 MB 94.5 kB/s eta 0:00:08\n",
      "     ---------------------                    0.8/1.5 MB 94.5 kB/s eta 0:00:08\n",
      "     ----------------------                   0.8/1.5 MB 95.8 kB/s eta 0:00:07\n",
      "     ----------------------                   0.8/1.5 MB 95.8 kB/s eta 0:00:07\n",
      "     ----------------------                   0.9/1.5 MB 97.0 kB/s eta 0:00:07\n",
      "     ----------------------                   0.9/1.5 MB 97.0 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 97.1 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 97.1 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 97.1 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 98.2 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 98.5 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 98.5 kB/s eta 0:00:07\n",
      "     -----------------------                  0.9/1.5 MB 98.5 kB/s eta 0:00:07\n",
      "     ------------------------                 0.9/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     ------------------------                 0.9/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     ------------------------                 0.9/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     -------------------------                0.9/1.5 MB 100.6 kB/s eta 0:00:06\n",
      "     -------------------------                0.9/1.5 MB 100.6 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.3 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.3 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.3 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.3 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.7 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.7 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.7 kB/s eta 0:00:06\n",
      "     -------------------------                1.0/1.5 MB 100.7 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.8 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.8 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.8 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.8 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.4 kB/s eta 0:00:06\n",
      "     --------------------------               1.0/1.5 MB 99.7 kB/s eta 0:00:05\n",
      "     --------------------------               1.0/1.5 MB 99.7 kB/s eta 0:00:05\n",
      "     --------------------------               1.0/1.5 MB 99.7 kB/s eta 0:00:05\n",
      "     ---------------------------              1.0/1.5 MB 100.5 kB/s eta 0:00:05\n",
      "     ---------------------------              1.0/1.5 MB 100.5 kB/s eta 0:00:05\n",
      "     ---------------------------              1.0/1.5 MB 100.5 kB/s eta 0:00:05\n",
      "     ---------------------------              1.0/1.5 MB 100.4 kB/s eta 0:00:05\n",
      "     ---------------------------              1.0/1.5 MB 100.4 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.4 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.4 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.4 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.1 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.1 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.1 kB/s eta 0:00:05\n",
      "     ----------------------------             1.1/1.5 MB 101.1 kB/s eta 0:00:05\n",
      "     -----------------------------            1.1/1.5 MB 101.3 kB/s eta 0:00:05\n",
      "     -----------------------------            1.1/1.5 MB 101.3 kB/s eta 0:00:05\n",
      "     -----------------------------            1.1/1.5 MB 101.3 kB/s eta 0:00:05\n",
      "     -----------------------------            1.1/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -----------------------------            1.1/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -----------------------------            1.1/1.5 MB 101.9 kB/s eta 0:00:04\n",
      "     -----------------------------            1.1/1.5 MB 101.9 kB/s eta 0:00:04\n",
      "     -----------------------------            1.1/1.5 MB 101.9 kB/s eta 0:00:04\n",
      "     ------------------------------           1.1/1.5 MB 102.8 kB/s eta 0:00:04\n",
      "     ------------------------------           1.1/1.5 MB 102.8 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     ------------------------------           1.2/1.5 MB 102.7 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.8 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     -------------------------------          1.2/1.5 MB 101.5 kB/s eta 0:00:04\n",
      "     --------------------------------         1.2/1.5 MB 100.4 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.4 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.4 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 100.8 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     --------------------------------         1.2/1.5 MB 99.3 kB/s eta 0:00:03\n",
      "     ---------------------------------        1.3/1.5 MB 98.3 kB/s eta 0:00:03\n",
      "     ---------------------------------        1.3/1.5 MB 98.3 kB/s eta 0:00:03\n",
      "     ---------------------------------        1.3/1.5 MB 98.3 kB/s eta 0:00:03\n",
      "     ---------------------------------        1.3/1.5 MB 98.3 kB/s eta 0:00:03\n",
      "     ---------------------------------        1.3/1.5 MB 98.3 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.9 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.9 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.9 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.9 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.9 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.2 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.0 kB/s eta 0:00:03\n",
      "     ----------------------------------       1.3/1.5 MB 97.0 kB/s eta 0:00:03\n",
      "     -----------------------------------      1.3/1.5 MB 97.1 kB/s eta 0:00:02\n",
      "     -----------------------------------      1.3/1.5 MB 97.1 kB/s eta 0:00:02\n",
      "     -----------------------------------      1.3/1.5 MB 97.1 kB/s eta 0:00:02\n",
      "     -----------------------------------      1.3/1.5 MB 97.6 kB/s eta 0:00:02\n",
      "     -----------------------------------      1.3/1.5 MB 97.6 kB/s eta 0:00:02\n",
      "     -----------------------------------      1.3/1.5 MB 97.6 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.9 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.9 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.9 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     ------------------------------------     1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 98.1 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 98.1 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 98.1 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 98.1 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 97.7 kB/s eta 0:00:02\n",
      "     -------------------------------------    1.4/1.5 MB 98.2 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 98.2 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 98.2 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.4/1.5 MB 98.8 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.4/1.5 MB 98.8 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.5 MB 98.8 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 99.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 99.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 99.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 100.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 100.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\roydo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\roydo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\roydo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roydo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\roydo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "# Ensure you have the necessary NLTK models downloaded\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    # Initialize the Punkt tokenizer\n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    \n",
    "    # Tokenize the text into sentences\n",
    "    sentences = tokenizer.tokenize(query)\n",
    "\n",
    "    # Check if the query is a simple one (contains only one sentence)\n",
    "    if len(sentences) == 1:\n",
    "        return sentences  # Return the single sentence wrapped in a list\n",
    "\n",
    "    # Combine into segments\n",
    "    combined = ''\n",
    "    segments = []\n",
    "\n",
    "    # Flag to check if last sentence was a question\n",
    "    last_was_question = False\n",
    "\n",
    "    # Loop through each sentence and decide whether to start a new segment\n",
    "    for sentence in sentences:\n",
    "        # If last sentence was a question and current isn't directly a question,\n",
    "        # start a new segment\n",
    "        if last_was_question and sentence.strip().endswith('?'):\n",
    "            segments.append(combined.strip())\n",
    "            combined = sentence + ' '\n",
    "            last_was_question = False\n",
    "        else:\n",
    "            combined += sentence + ' '\n",
    "\n",
    "        # Check if current sentence ends with a question mark\n",
    "        if sentence.strip().endswith('?'):\n",
    "            last_was_question = True\n",
    "\n",
    "    # Append the last segment if there's any remaining text\n",
    "    if combined:\n",
    "        segments.append(combined.strip())\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 processed: ['How are you Roydon? I heard you have a new pet dog.', 'How have you been?']\n",
      "Query 2 processed: [\"What's the weather like today?\"]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"How are you Roydon? I heard you have a new pet dog. How have you been?\"\n",
    "query2 = \"What's the weather like today?\"\n",
    "\n",
    "# Process the queries\n",
    "result1 = process_query(query1)\n",
    "result2 = process_query(query2)\n",
    "\n",
    "print(\"Query 1 processed:\", result1)\n",
    "print(\"Query 2 processed:\", result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v3 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v3\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 61 documents.\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\documents.json'\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    documents_json = json.load(json_file)\n",
    "\n",
    "# Convert the JSON serializable format back to Document objects\n",
    "documents = [\n",
    "    Document(page_content=doc['page_content'], metadata=doc['metadata'])\n",
    "    for doc in documents_json\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v3.as_retriever(search_kwargs={\"k\": 6})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  6\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That's awesome! What breed is it?\"}{\"Roydon\": \"I couldn't agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It's amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}{\"Roydon\": \"I'm thinking of naming him Sunny, because he brings so much joy and sunshine into my life. What do you think?\", \"Xavier\": \"Sunny is a perfect name for a golden retriever! It suits his happy and cheerful personality. I can't wait to see all the fun adventures you two will have together.\"}{\"Roydon\": \"Guess what, I just got a new pet dog!\", \"Jacob\": \"That's awesome! What breed is it?\"}{\"Roydon\": \"I couldn't agree more, I feel like my new dog has completed my little family.\", \"Jacob\": \"It's amazing how pets have a way of making a house feel like a home, enjoy every moment with your furry friend!\"}{\"Roydon\": \"I'm thinking of naming him Sunny, because he brings so much joy and sunshine into my life. What do you think?\", \"Xavier\": \"Sunny is a perfect name for a golden retriever! It suits his happy and cheerful personality. I can't wait to see all the fun adventures you two will have together.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"I heard you got a new pet dog how is he? What are you going to name him?\"\n",
    "contexts = \"\"\n",
    "query_split = process_query(query)\n",
    "for i in query_split:\n",
    "    # Obtain top 3 filtered docs\n",
    "    docs_rel=ensemble_retriever.get_relevant_documents(query)\n",
    "    topic_interpreted = getTopic(meta_content, query)\n",
    "    final_docs = filter_list(docs_rel, topic_interpreted) # Still top 3\n",
    "    for context in final_docs:\n",
    "        contexts += context.page_content\n",
    "\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data_sample = {\n",
    "    'question': [\n",
    "        'What have you been up to Roydon?',\n",
    "        'Woah really how is Arsenal doing right now then?',\n",
    "        'Nice what breed is your new pet dog?',\n",
    "        'So what you planning to do with your pet dog?',\n",
    "        'How was your trip to thailand?',\n",
    "        'What happened in thailand?',\n",
    "        'What channel are you planning to create for your new pet dog?',\n",
    "        #------------ Dual questions\n",
    "        'How was your trip to thailand? Any new travel plans next year?',\n",
    "        'I heard you got a new pet dog how is he? What are you going to name him?',\n",
    "        'Hows your new pet dog? What breed is he?'\n",
    "        #------------ Complicated questions\n",
    "        \n",
    "    ],\n",
    "    'answer': [],\n",
    "    'contexts': [],\n",
    "    'ground_truth': [\n",
    "        \"Response 1: I've been watching Arsenal games hoping they will win. Response 2: I've been looking at a trip to Japan. Response 3: I just got a new pet dog. How about you?\",\n",
    "        \"Response 1: Arsenal is doing well, did you catch the match yesterday? Response 2: Arsenal is doing great and Aubameyang is a true asset to the team. Response 3: Arsenal is doing alright since Ben White is a great addition to the team.\",\n",
    "        \"Response 1: He is a golden retriever, and he's the cutest thing ever! Response 2: He is a golden retriever, and he's the cutest thing ever! Response 3: He is a golden retriever, and he's the cutest thing ever!\",\n",
    "        \"Response 1: I'm planning to take him on long hikes on the mountain. Response 2: I'm planning to take him to the beach and watch him splash in the waves. Response 3: I'm planning for play dates with other dogs.\",\n",
    "        \"Response 1: It was a horrible experience and I would never go back. Response 2: It was a horrible experience and I would never go back. Response 3: It was a horrible experience and I would never go back.\",\n",
    "        \"Response 1: I got scammed by a taxi driver and lost all my money. Response 2: The hotel lost my reservation and I had to sleep on the streets. Response 3: I kept getting ripped off by the locals and it was such a horrible experience.\",\n",
    "        \"Response 1: I'm planning to create a special Instagram account just for him to share our adventures. Response 2: I'm planning to create a special Instagram account just for him to share our adventures. Response 3: I'm planning to create a special Instagram account just for him to share our adventures.\",\n",
    "        \"Response 1: It was a horrible experience. I got scammed by a taxi driver and lost all my money. Response 2: It was a horrible experience. The hotel lost my reservation and I had to sleep on the streets. Response 3: It was a horrible experience. I kept getting ripped off by the locals.\",\n",
    "        \"Response 1: He is so fun to be with. Im planning to name him Sunny. Response 2: He is so fun to be with. Im planning to name him Sunny. Response 3: He is so fun to be with. Im planning to name him Sunny.\",\n",
    "        \"Response 1: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 2: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever! Response 3: He brings so much joy to my life. He is a golden retriever, and he's the cutest thing ever!\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")\n",
    "\n",
    "## Load Vector Store\n",
    "loaded_faiss_vs_hf_v3 = FAISS.load_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\\\vector_store\\\\vectorstores\\\\hugging_face\\\\faiss_vs_hf_v3\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 61 documents.\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\backend\\mockdata\\\\documents.json'\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    documents_json = json.load(json_file)\n",
    "\n",
    "# Convert the JSON serializable format back to Document objects\n",
    "documents = [\n",
    "    Document(page_content=doc['page_content'], metadata=doc['metadata'])\n",
    "    for doc in documents_json\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate retriever\n",
    "retriever_vectordb = loaded_faiss_vs_hf_v3.as_retriever(search_kwargs={\"k\": 6})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k =  6\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb,keyword_retriever],\n",
    "                                       weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate meta content\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Roydon\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Roydon! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Roydon\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Roydon\": \"Hey there! How are you doing?\", \"John\": \"Hey Roydon! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pet\n"
     ]
    }
   ],
   "source": [
    "import inflect\n",
    "\n",
    "def singularize_and_lower(topic):\n",
    "    # Create an inflect engine for handling plurals\n",
    "    engine = inflect.engine()\n",
    "    \n",
    "    # Lowercase the topic\n",
    "    topic = topic.lower()\n",
    "    \n",
    "    # Singularize the topic (convert plurals to singular), returns false if not noun\n",
    "    topic = engine.singular_noun(topic) if engine.singular_noun(topic) else topic\n",
    "    \n",
    "    return topic\n",
    "\n",
    "print(singularize_and_lower(\"pets\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def filter_list(docs_rel, topic):\n",
    "    # Filter according to the topic\n",
    "    filtered_docs = []\n",
    "    final_docs = []\n",
    "    general_topic = {}\n",
    "\n",
    "    if singularize_and_lower(topic) == \"general\":\n",
    "        for doc in docs_rel:\n",
    "            if singularize_and_lower(doc.metadata['topic']) not in general_topic:\n",
    "                general_topic[singularize_and_lower(doc.metadata['topic'])] = 1\n",
    "                filtered_docs.append(doc)\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for doc in docs_rel:\n",
    "            if(singularize_and_lower(doc.metadata['topic']) == singularize_and_lower(topic)):\n",
    "                filtered_docs.append(doc)\n",
    "       \n",
    "    if len(filtered_docs) > 2:\n",
    "        final_docs = filtered_docs[:3]\n",
    "        return final_docs\n",
    "    else:\n",
    "        count = 3 - len(filtered_docs)\n",
    "        final_docs = filtered_docs\n",
    "        position = 0\n",
    "        for i in range(count):\n",
    "            if(position == len(docs_rel)):\n",
    "                break\n",
    "            if(docs_rel[position] in filtered_docs):\n",
    "                i = i-1\n",
    "                position += 1\n",
    "                continue\n",
    "            else:\n",
    "                final_docs.append(docs_rel[position])# need to change so that it wont be same obtained\n",
    "                position+=1 \n",
    "        \n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Generate for rag\n",
    "for query in data_sample['question']:\n",
    "    # Get contexts for query\n",
    "    contexts = \"\"\n",
    "    query_split = process_query(query)\n",
    "    for i in query_split:\n",
    "        # Obtain top 3 filtered docs\n",
    "        docs_rel=ensemble_retriever.get_relevant_documents(i)\n",
    "        topic_interpreted = getTopic(meta_content, i)\n",
    "        final_docs = filter_list(docs_rel, topic_interpreted) # Still top 3\n",
    "        for context in final_docs:\n",
    "            contexts += context.page_content\n",
    "\n",
    "    data_sample['contexts'].append([contexts])\n",
    "\n",
    "    content = f\"\"\"You are an assistant whom will faciliate the conversation between a mute and a normal person. The mute persons name is Roydon and the normal person is indicated as other person.\n",
    "                        You should be generating 3 responses which the mute person could choose from and the responses generated should follow the context of the conversation. \n",
    "                        The responses should be what a person would say and should not include actions in a third person view. Your persona would be from the perspective of the mute person.\n",
    "\n",
    "                        Snippets of conversation would be given below in the section of Context. Use the conversations to assist in the generation the 3 responses. Primarily the topic should be inferred from the question asked but if no topic can be inferred, infer the topics from the conversations given in the context. The conversations are seperated by \"{{\" and \"}}\":\\n\n",
    "                        Context: {contexts}\n",
    "\n",
    "                        For example, if the context above contains \"{{\"Roydon\": \"Recently my new pet dog has been so fun!\", \"Jacob\": \"That\\'s awesome! What breed is it?\"}}\"\n",
    "\n",
    "                        If the user asks \"What have you been up to?\"\n",
    "\n",
    "                        An example of the 3 generated response would be in the format of 1 single string \"Response 1: I have been playing with my new pet dog. Response 2: Nothing much, I recently brought my new pet dog to a park. Response 3: Its been tiring lately after getting a new pet dog. \"\"\"\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Other person says: \" + query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "    \n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    response_choices = raw_response.choices[0].message.content\n",
    "    data_sample['answer'].append(response_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path (v1 is before the changed filtered list)\n",
    "file_path = 'testing_json/Improve_RAG/meta_filter_v3.json'\n",
    "\n",
    "# Save the data_sample dictionary into a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data_sample, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAGAS And G-Eval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# RAGAS \n",
    "file_path_meta_filter = 'testing_json/Improve_RAG/meta_filter_v3.json'\n",
    "\n",
    "with open(file_path_meta_filter, 'r') as json_file:\n",
    "    rag_ensemble_meta_filter_query_altered = json.load(json_file)\n",
    "\n",
    "rag_dataset_query_altered_meta_filter = Dataset.from_dict(rag_ensemble_meta_filter_query_altered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 40/40 [00:35<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "rag_dataset_ensemble_meta_filter_query_altered_score = evaluate(rag_dataset_query_altered_meta_filter, metrics=[answer_relevancy, answer_correctness,context_precision, context_recall])\n",
    "\n",
    "rag_ensemble_meta_filter_query_altered_df = rag_dataset_ensemble_meta_filter_query_altered_score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What have you been up to Roydon?</td>\n",
       "      <td>Response 1: I tried to, but everywhere I went,...</td>\n",
       "      <td>['{\"Roydon\": \"I tried to, but everywhere I wen...</td>\n",
       "      <td>Response 1: I've been watching Arsenal games h...</td>\n",
       "      <td>0.874612</td>\n",
       "      <td>0.213545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.389333</td>\n",
       "      <td>Some parts of the actual output do not match a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Woah really how is Arsenal doing right now then?</td>\n",
       "      <td>Response 1: Arsenal is currently showing great...</td>\n",
       "      <td>['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...</td>\n",
       "      <td>Response 1: Arsenal is doing well, did you cat...</td>\n",
       "      <td>0.754243</td>\n",
       "      <td>0.603599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.610755</td>\n",
       "      <td>Two out of the three responses in the actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice what breed is your new pet dog?</td>\n",
       "      <td>Response 1: It's a golden retriever, and he's ...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>0.941946</td>\n",
       "      <td>0.738309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879030</td>\n",
       "      <td>The main content of the responses generated cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>So what you planning to do with your pet dog?</td>\n",
       "      <td>Response 1: I'm planning to teach him how to f...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to take him on long h...</td>\n",
       "      <td>0.544969</td>\n",
       "      <td>0.608215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.558312</td>\n",
       "      <td>The main content of some responses in the actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How was your trip to thailand?</td>\n",
       "      <td>Response 1: Thailand was a disaster, everythin...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe how terrible my...</td>\n",
       "      <td>Response 1: It was a horrible experience and I...</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.803058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873509</td>\n",
       "      <td>The main content of all actual responses match...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What happened in thailand?</td>\n",
       "      <td>Response 1: It was a series of unfortunate eve...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t believe what happened t...</td>\n",
       "      <td>Response 1: I got scammed by a taxi driver and...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.589833</td>\n",
       "      <td>Only one of the main content of the responses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What channel are you planning to create for yo...</td>\n",
       "      <td>Response 1: I'm thinking of creating a channel...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: I'm planning to create a special I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784435</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How was your trip to thailand? Any new travel ...</td>\n",
       "      <td>Response 1: Thailand was a disaster, but I'm e...</td>\n",
       "      <td>['{\"Roydon\": \"I can\\'t wait to immerse myself ...</td>\n",
       "      <td>Response 1: It was a horrible experience. I go...</td>\n",
       "      <td>0.789362</td>\n",
       "      <td>0.723084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.591981</td>\n",
       "      <td>The main content of the responses in 'actual o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>I heard you got a new pet dog how is he? What ...</td>\n",
       "      <td>Response 1: He's been great so far, very playf...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He is so fun to be with. Im planni...</td>\n",
       "      <td>0.888668</td>\n",
       "      <td>0.981320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851740</td>\n",
       "      <td>The main content of the responses in the 'actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hows your new pet dog? What breed is he?</td>\n",
       "      <td>Response 1: He is a golden retriever, and he's...</td>\n",
       "      <td>['{\"Roydon\": \"Guess what, I just got a new pet...</td>\n",
       "      <td>Response 1: He brings so much joy to my life. ...</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>0.236593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744463</td>\n",
       "      <td>The main content of the responses generated is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                   What have you been up to Roydon?   \n",
       "1           1   Woah really how is Arsenal doing right now then?   \n",
       "2           2               Nice what breed is your new pet dog?   \n",
       "3           3      So what you planning to do with your pet dog?   \n",
       "4           4                     How was your trip to thailand?   \n",
       "5           5                         What happened in thailand?   \n",
       "6           6  What channel are you planning to create for yo...   \n",
       "7           7  How was your trip to thailand? Any new travel ...   \n",
       "8           8  I heard you got a new pet dog how is he? What ...   \n",
       "9           9           Hows your new pet dog? What breed is he?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Response 1: I tried to, but everywhere I went,...   \n",
       "1  Response 1: Arsenal is currently showing great...   \n",
       "2  Response 1: It's a golden retriever, and he's ...   \n",
       "3  Response 1: I'm planning to teach him how to f...   \n",
       "4  Response 1: Thailand was a disaster, everythin...   \n",
       "5  Response 1: It was a series of unfortunate eve...   \n",
       "6  Response 1: I'm thinking of creating a channel...   \n",
       "7  Response 1: Thailand was a disaster, but I'm e...   \n",
       "8  Response 1: He's been great so far, very playf...   \n",
       "9  Response 1: He is a golden retriever, and he's...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['{\"Roydon\": \"I tried to, but everywhere I wen...   \n",
       "1  ['{\"Roydon\": \"I couldn\\'t agree more! Aubameya...   \n",
       "2  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "3  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "4  ['{\"Roydon\": \"I can\\'t believe how terrible my...   \n",
       "5  ['{\"Roydon\": \"I can\\'t believe what happened t...   \n",
       "6  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "7  ['{\"Roydon\": \"I can\\'t wait to immerse myself ...   \n",
       "8  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "9  ['{\"Roydon\": \"Guess what, I just got a new pet...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Response 1: I've been watching Arsenal games h...          0.874612   \n",
       "1  Response 1: Arsenal is doing well, did you cat...          0.754243   \n",
       "2  Response 1: He is a golden retriever, and he's...          0.941946   \n",
       "3  Response 1: I'm planning to take him on long h...          0.544969   \n",
       "4  Response 1: It was a horrible experience and I...          0.995870   \n",
       "5  Response 1: I got scammed by a taxi driver and...          0.000000   \n",
       "6  Response 1: I'm planning to create a special I...          0.000000   \n",
       "7  Response 1: It was a horrible experience. I go...          0.789362   \n",
       "8  Response 1: He is so fun to be with. Im planni...          0.888668   \n",
       "9  Response 1: He brings so much joy to my life. ...          0.933533   \n",
       "\n",
       "   answer_correctness  context_precision  context_recall    Scores  \\\n",
       "0            0.213545                0.0        0.333333  0.389333   \n",
       "1            0.603599                1.0        0.666667  0.610755   \n",
       "2            0.738309                1.0        1.000000  0.879030   \n",
       "3            0.608215                1.0        0.666667  0.558312   \n",
       "4            0.803058                1.0        1.000000  0.873509   \n",
       "5            0.215579                1.0        0.333333  0.589833   \n",
       "6            0.558308                1.0        1.000000  0.784435   \n",
       "7            0.723084                1.0        0.666667  0.591981   \n",
       "8            0.981320                1.0        1.000000  0.851740   \n",
       "9            0.236593                1.0        1.000000  0.744463   \n",
       "\n",
       "                                             Reasons  \n",
       "0  Some parts of the actual output do not match a...  \n",
       "1  Two out of the three responses in the actual o...  \n",
       "2  The main content of the responses generated cl...  \n",
       "3  The main content of some responses in the actu...  \n",
       "4  The main content of all actual responses match...  \n",
       "5  Only one of the main content of the responses ...  \n",
       "6  The main content of the responses in the 'actu...  \n",
       "7  The main content of the responses in 'actual o...  \n",
       "8  The main content of the responses in the 'actu...  \n",
       "9  The main content of the responses generated is...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load 0.7 0.3 scores\n",
    "\n",
    "excel_file_path = 'scorings\\RAG_Prompt_Engineered\\RAG Improvement\\Ensemble HF\\Combined_Ensemble_meta_filtered.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "meta_filtered = pd.read_excel(excel_file_path)\n",
    "\n",
    "meta_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load 0.7 0.3 scores\n",
    "\n",
    "excel_file_path = 'scorings\\RAG_Prompt_Engineered\\RAG Improvement\\Ensemble HF\\Combined_Ensemble_meta_filtered_Query_Altered_v2.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "rag_ensemble_meta_filter_query_altered_df = pd.read_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Ensemble Meta Filtered=========================\n",
      "RAG Average Answer Relevancy: 0.6723204037179018\n",
      "RAG Average Answer Correctness: 0.568161100684651\n",
      "RAG Average Context Precision: 0.89999999991\n",
      "RAG Average Context Recall: 0.7666666666666666\n",
      "=========================Ensemble Meta Filtered Query Altered=========================\n",
      "RAG Average Answer Relevancy: 0.6798901851761995\n",
      "RAG Average Answer Correctness: 0.6569532556501141\n",
      "RAG Average Context Precision: 0.9\n",
      "RAG Average Context Recall: 0.7666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Calculate average for meta_filtered\n",
    "rag_ensemble_meta_filter_avg_answer_relevancy = meta_filtered['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_answer_correctness = meta_filtered['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_precision = meta_filtered['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_meta_filter_avg_recall = meta_filtered['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Calculate average for query altering\n",
    "rag_ensemble_query_alter_avg_answer_relevancy = rag_ensemble_meta_filter_query_altered_df['answer_relevancy'].mean(skipna=True)\n",
    "rag_ensemble_query_alter_avg_answer_correctness = rag_ensemble_meta_filter_query_altered_df['answer_correctness'].mean(skipna=True)\n",
    "rag_ensemble_query_alter_avg_precision = rag_ensemble_meta_filter_query_altered_df['context_precision'].mean(skipna=True)\n",
    "rag_ensemble_query_alter_avg_recall = rag_ensemble_meta_filter_query_altered_df['context_recall'].mean(skipna=True)\n",
    "\n",
    "# Print the averages\n",
    "print(\"=========================Ensemble Meta Filtered=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_meta_filter_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_meta_filter_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_meta_filter_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_meta_filter_avg_recall)\n",
    "print(\"=========================Ensemble Meta Filtered Query Altered=========================\")\n",
    "print(\"RAG Average Answer Relevancy:\", rag_ensemble_query_alter_avg_answer_relevancy)\n",
    "print(\"RAG Average Answer Correctness:\", rag_ensemble_query_alter_avg_answer_correctness)\n",
    "print(\"RAG Average Context Precision:\", rag_ensemble_query_alter_avg_precision)\n",
    "print(\"RAG Average Context Recall:\", rag_ensemble_query_alter_avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/ensemble_meta_filter_scores_v3.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "rag_ensemble_meta_filter_query_altered_df.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.0.6, however version 1.2.4 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# G-eval\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "correctness_metric = GEval(\n",
    "    name=\"Relevance\",\n",
    "    #criteria=\"Determine whether the actual output matches the expected output as close as possible.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the main content of the responses generated in 'actual output' are similar to the responses in the 'expected output'\",\n",
    "        \"\"\"As long as one of the main content of the responses generated is similar to any of the expected output, the test case is considered correct.\n",
    "        For example, if response 1 content is on a pet dog and it matches response 3 content of also a pet dog, give it a high score. \n",
    "        The order of the responses is not important.\"\"\",\n",
    "        \"Evaluate mainly based on main content but do still give a higher score depending on similarity of responses.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\roydo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensemble_open_hf scores\n",
    "ensemble_meta_filter_query_altered_scores = []\n",
    "ensemble_meta_filter_query_altered_reasons = []\n",
    "\n",
    "\n",
    "for i in range(len(rag_dataset_query_altered_meta_filter['question'])):\n",
    "    test_case = LLMTestCase(\n",
    "        input=rag_dataset_query_altered_meta_filter['question'][i],\n",
    "        actual_output=rag_dataset_query_altered_meta_filter['answer'][i],\n",
    "        expected_output=rag_dataset_query_altered_meta_filter['ground_truth'][i]\n",
    "    )\n",
    "\n",
    "    correctness_metric.measure(test_case)\n",
    "    # print(correctness_metric.score)\n",
    "    # print(correctness_metric.reason)\n",
    "    ensemble_meta_filter_query_altered_scores.append(correctness_metric.score)\n",
    "    ensemble_meta_filter_query_altered_reasons.append(correctness_metric.reason)\n",
    "\n",
    "# print(ensemble_open_ai_scores)\n",
    "# print(ensemble_open_ai_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for Ensemble HF Meta Filtered: 0.6873390817852749\n",
      "Average Score for Ensemble HF Meta Filtered Query Altered: 0.7141140981676445\n"
     ]
    }
   ],
   "source": [
    "# Combine scores and reasons into a DataFrame\n",
    "ensemble_hf_df_meta_filter_query_altered = pd.DataFrame({'Scores': ensemble_meta_filter_query_altered_scores, 'Reasons': ensemble_meta_filter_query_altered_reasons})\n",
    "\n",
    "# Calculate the average scores for each DataFrame\n",
    "ensemble_hf_meta_filter = meta_filtered['Scores'].mean()\n",
    "ensemble_hf_meta_filter_query_altered = ensemble_hf_df_meta_filter_query_altered['Scores'].mean()\n",
    "\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Score for Ensemble HF Meta Filtered:\", ensemble_hf_meta_filter)\n",
    "print(\"Average Score for Ensemble HF Meta Filtered Query Altered:\", ensemble_hf_meta_filter_query_altered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the Excel file\n",
    "excel_file_path = 'scorings/RAG_Prompt_Engineered/RAG Improvement/Ensemble HF/g_eval_ensemble_meta_filtered_v3.xlsx'\n",
    "\n",
    "# Store the DataFrame into an Excel file\n",
    "ensemble_hf_df_meta_filter_query_altered.to_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
